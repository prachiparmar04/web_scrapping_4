{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment-4 WEB SCRAPPING WITH SELENIUM AND BEAUTIFUL SOUP\n",
    "\n",
    "\n",
    "### Scrape the details of most viewed videos on YouTube from Wikipedia:\n",
    "    Url = https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos/\n",
    "    You need to find following details:\n",
    "    A) Rank\n",
    "    B) Name\n",
    "    C) Artist\n",
    "    D) Upload date\n",
    "    E) Views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing all necessary imports for Beutiful Soup and Selenium library\n",
    "import pandas as pd\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException, ElementNotInteractableException\n",
    "import requests\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "\n",
    "\n",
    "import selenium \n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORTING chrome driver exe\n",
    "\n",
    "\n",
    "driver = webdriver.Chrome(\"Downloads\\chromedriver_win32\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading url to the chrome driver\n",
    "\n",
    "url = 'https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos'\n",
    "driver.get(url)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "#creating list for rank, uploader)name, video name, no of views, date of upload\n",
    "rank = []\n",
    "video_names = []\n",
    "video_uploader_name = []\n",
    "views = []\n",
    "upload_dates = []\n",
    "\n",
    "\n",
    "    #RANK ELEMENT\n",
    "try:\n",
    "    rank_obj = driver.find_elements_by_xpath('//table[@class=\"wikitable sortable jquery-tablesorter\"]/tbody/tr/td[1]')[:30]\n",
    "    for i in rank_obj:\n",
    "        rank.append(i.text)\n",
    "except NoSuchElementException :\n",
    "    rank.append('-')\n",
    "    \n",
    "    \n",
    "   #VIDEO NAME ELEMENT\n",
    "try:\n",
    "    videoname_obj = driver.find_elements_by_xpath('//table[@class=\"wikitable sortable jquery-tablesorter\"]/tbody/tr/td[2]')[:30]\n",
    "    for i in videoname_obj:\n",
    "        video_names.append(i.text.split('[')[0][1:-1])\n",
    "except NoSuchElementException :\n",
    "    video_names.append('-')\n",
    "    \n",
    "    \n",
    "    \n",
    "    #UPLOADER_OF_VIDEO\n",
    "try:\n",
    "    uploader_obj = driver.find_elements_by_xpath('//table[@class=\"wikitable sortable jquery-tablesorter\"]/tbody/tr/td[3]')[:30]\n",
    "    for i in uploader_obj:\n",
    "        video_uploader_name.append(i.text)\n",
    "except NoSuchElementException :\n",
    "    video_uploader_name.append('-')\n",
    "    \n",
    "    \n",
    "\n",
    "    #VIEWS ON THE VIDEOS\n",
    "try:\n",
    "    view_obj = driver.find_elements_by_xpath('//table[@class=\"wikitable sortable jquery-tablesorter\"]/tbody/tr/td[4]')[:30]\n",
    "    for i in view_obj:\n",
    "        views.append(i.text)\n",
    "except NoSuchElementException :\n",
    "    views.append('-')\n",
    "    \n",
    "    \n",
    "    #DATE OF THE VIDEO ELEMENT\n",
    "try:\n",
    "    date_obj = driver.find_elements_by_xpath('//table[@class=\"wikitable sortable jquery-tablesorter\"]/tbody/tr/td[5]')[:30]\n",
    "    for i in date_obj:\n",
    "        upload_dates.append(i.text)\n",
    "except NoSuchElementException :\n",
    "    upload_dates.append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a diction of all the columns\n",
    "dict = {'rank':rank, 'video_name':video_names,'uploader':video_uploader_name,'Views in Billions':views,'upload_date':upload_dates}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATING TABLE / dATA fRAME OF THE DICTIONARY\n",
    "table = pd.DataFrame(dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>video_name</th>\n",
       "      <th>uploader</th>\n",
       "      <th>Views in Billions</th>\n",
       "      <th>upload_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.</td>\n",
       "      <td>Baby Shark Dance</td>\n",
       "      <td>Pinkfong Kids' Songs &amp; Stories</td>\n",
       "      <td>8.95</td>\n",
       "      <td>June 17, 2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.</td>\n",
       "      <td>Despacito</td>\n",
       "      <td>Luis Fonsi</td>\n",
       "      <td>7.44</td>\n",
       "      <td>January 12, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.</td>\n",
       "      <td>Johny Johny Yes Papa</td>\n",
       "      <td>LooLoo Kids</td>\n",
       "      <td>5.54</td>\n",
       "      <td>October 8, 2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.</td>\n",
       "      <td>Shape of You</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>5.38</td>\n",
       "      <td>January 30, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.</td>\n",
       "      <td>See You Again</td>\n",
       "      <td>Wiz Khalifa</td>\n",
       "      <td>5.17</td>\n",
       "      <td>April 6, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.</td>\n",
       "      <td>Masha and the Bear – Recipe for Disaster</td>\n",
       "      <td>Get Movies</td>\n",
       "      <td>4.44</td>\n",
       "      <td>January 31, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.</td>\n",
       "      <td>Bath Song</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>4.29</td>\n",
       "      <td>May 2, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.</td>\n",
       "      <td>Learning Colors – Colorful Eggs on a Farm</td>\n",
       "      <td>Miroshka TV</td>\n",
       "      <td>4.25</td>\n",
       "      <td>February 27, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.</td>\n",
       "      <td>Uptown Funk</td>\n",
       "      <td>Mark Ronson</td>\n",
       "      <td>4.22</td>\n",
       "      <td>November 19, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.</td>\n",
       "      <td>Gangnam Style</td>\n",
       "      <td>Psy</td>\n",
       "      <td>4.11</td>\n",
       "      <td>July 15, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11.</td>\n",
       "      <td>Phonics Song with Two Words</td>\n",
       "      <td>ChuChu TV</td>\n",
       "      <td>3.98</td>\n",
       "      <td>March 6, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12.</td>\n",
       "      <td>Sugar</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>3.50</td>\n",
       "      <td>January 14, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13.</td>\n",
       "      <td>Dame Tu Cosita</td>\n",
       "      <td>El Chombo</td>\n",
       "      <td>3.45</td>\n",
       "      <td>April 5, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14.</td>\n",
       "      <td>Sorry</td>\n",
       "      <td>Justin Bieber</td>\n",
       "      <td>3.45</td>\n",
       "      <td>October 22, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15.</td>\n",
       "      <td>Roar</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>3.38</td>\n",
       "      <td>September 5, 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16.</td>\n",
       "      <td>Counting Stars</td>\n",
       "      <td>OneRepublic</td>\n",
       "      <td>3.34</td>\n",
       "      <td>May 31, 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17.</td>\n",
       "      <td>Thinking Out Loud</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>3.29</td>\n",
       "      <td>October 7, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18.</td>\n",
       "      <td>Wheels on the Bus</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>3.15</td>\n",
       "      <td>May 24, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19.</td>\n",
       "      <td>Dark Horse</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>3.10</td>\n",
       "      <td>February 20, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20.</td>\n",
       "      <td>Faded</td>\n",
       "      <td>Alan Walker</td>\n",
       "      <td>3.10</td>\n",
       "      <td>December 3, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21.</td>\n",
       "      <td>Shake It Off</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>3.07</td>\n",
       "      <td>August 18, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22.</td>\n",
       "      <td>Girls Like You</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>3.07</td>\n",
       "      <td>May 31, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23.</td>\n",
       "      <td>Lean On</td>\n",
       "      <td>Major Lazer</td>\n",
       "      <td>3.06</td>\n",
       "      <td>March 22, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24.</td>\n",
       "      <td>Bailando</td>\n",
       "      <td>Enrique Iglesias</td>\n",
       "      <td>3.06</td>\n",
       "      <td>April 11, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25.</td>\n",
       "      <td>Let Her Go</td>\n",
       "      <td>Passenger</td>\n",
       "      <td>3.02</td>\n",
       "      <td>July 25, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26.</td>\n",
       "      <td>Mi Gente</td>\n",
       "      <td>J Balvin</td>\n",
       "      <td>2.94</td>\n",
       "      <td>June 29, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27.</td>\n",
       "      <td>Perfect</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>2.89</td>\n",
       "      <td>November 9, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28.</td>\n",
       "      <td>Waka Waka (This Time for Africa)</td>\n",
       "      <td>Shakira</td>\n",
       "      <td>2.88</td>\n",
       "      <td>June 4, 2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29.</td>\n",
       "      <td>Axel F</td>\n",
       "      <td>Crazy Frog</td>\n",
       "      <td>2.87</td>\n",
       "      <td>June 16, 2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30.</td>\n",
       "      <td>Hello</td>\n",
       "      <td>Adele</td>\n",
       "      <td>2.85</td>\n",
       "      <td>October 22, 2015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rank                                 video_name  \\\n",
       "0    1.                           Baby Shark Dance   \n",
       "1    2.                                  Despacito   \n",
       "2    3.                       Johny Johny Yes Papa   \n",
       "3    4.                               Shape of You   \n",
       "4    5.                              See You Again   \n",
       "5    6.   Masha and the Bear – Recipe for Disaster   \n",
       "6    7.                                  Bath Song   \n",
       "7    8.  Learning Colors – Colorful Eggs on a Farm   \n",
       "8    9.                                Uptown Funk   \n",
       "9   10.                              Gangnam Style   \n",
       "10  11.                Phonics Song with Two Words   \n",
       "11  12.                                      Sugar   \n",
       "12  13.                             Dame Tu Cosita   \n",
       "13  14.                                      Sorry   \n",
       "14  15.                                       Roar   \n",
       "15  16.                             Counting Stars   \n",
       "16  17.                          Thinking Out Loud   \n",
       "17  18.                          Wheels on the Bus   \n",
       "18  19.                                 Dark Horse   \n",
       "19  20.                                      Faded   \n",
       "20  21.                               Shake It Off   \n",
       "21  22.                             Girls Like You   \n",
       "22  23.                                    Lean On   \n",
       "23  24.                                   Bailando   \n",
       "24  25.                                 Let Her Go   \n",
       "25  26.                                   Mi Gente   \n",
       "26  27.                                    Perfect   \n",
       "27  28.           Waka Waka (This Time for Africa)   \n",
       "28  29.                                     Axel F   \n",
       "29  30.                                      Hello   \n",
       "\n",
       "                          uploader Views in Billions        upload_date  \n",
       "0   Pinkfong Kids' Songs & Stories              8.95      June 17, 2016  \n",
       "1                       Luis Fonsi              7.44   January 12, 2017  \n",
       "2                      LooLoo Kids              5.54    October 8, 2016  \n",
       "3                       Ed Sheeran              5.38   January 30, 2017  \n",
       "4                      Wiz Khalifa              5.17      April 6, 2015  \n",
       "5                       Get Movies              4.44   January 31, 2012  \n",
       "6       Cocomelon – Nursery Rhymes              4.29        May 2, 2018  \n",
       "7                      Miroshka TV              4.25  February 27, 2018  \n",
       "8                      Mark Ronson              4.22  November 19, 2014  \n",
       "9                              Psy              4.11      July 15, 2012  \n",
       "10                       ChuChu TV              3.98      March 6, 2014  \n",
       "11                        Maroon 5              3.50   January 14, 2015  \n",
       "12                       El Chombo              3.45      April 5, 2018  \n",
       "13                   Justin Bieber              3.45   October 22, 2015  \n",
       "14                      Katy Perry              3.38  September 5, 2013  \n",
       "15                     OneRepublic              3.34       May 31, 2013  \n",
       "16                      Ed Sheeran              3.29    October 7, 2014  \n",
       "17      Cocomelon – Nursery Rhymes              3.15       May 24, 2018  \n",
       "18                      Katy Perry              3.10  February 20, 2014  \n",
       "19                     Alan Walker              3.10   December 3, 2015  \n",
       "20                    Taylor Swift              3.07    August 18, 2014  \n",
       "21                        Maroon 5              3.07       May 31, 2018  \n",
       "22                     Major Lazer              3.06     March 22, 2015  \n",
       "23                Enrique Iglesias              3.06     April 11, 2014  \n",
       "24                       Passenger              3.02      July 25, 2012  \n",
       "25                        J Balvin              2.94      June 29, 2017  \n",
       "26                      Ed Sheeran              2.89   November 9, 2017  \n",
       "27                         Shakira              2.88       June 4, 2010  \n",
       "28                      Crazy Frog              2.87      June 16, 2009  \n",
       "29                           Adele              2.85   October 22, 2015  "
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape the details team India’s international fixtures from bcci.tv.\n",
    "Url = https://www.bcci.tv/.\n",
    "You need to find following details:\n",
    "A) Match title (I.e. 1st ODI)\n",
    "B) Series\n",
    "C) Place\n",
    "D) Date\n",
    "E) Time\n",
    "Note: - From bcci.tv home page you have reach to the international fixture page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "#giving the  bcci link to the driver to load in the browser\n",
    "driver.get('https://www.bcci.tv/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding the object of the international fixture matches from the dropdown element\n",
    "\n",
    "internation_fixtures_obj = driver.find_element_by_xpath('/html/body/div[3]/div/div[2]/div[2]/nav/ul/li[1]/div[2]/div/ul/li[1]/a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.bcci.tv/international/fixtures'"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#link of the dorpdown eleemnt international fixtures.\n",
    "link = internation_fixtures_obj.get_attribute('href')\n",
    "link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "#navigating to the international fixtures link.\n",
    "\n",
    "driver.get(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = []\n",
    "time = []\n",
    "series = []\n",
    "place = []\n",
    "match_title = []\n",
    "match_details = []\n",
    "\n",
    "# MERging Month and Day together for Date OBject\n",
    "try :\n",
    "    month_obj = driver.find_elements_by_xpath('//span[@class=\"fixture__month\"]')\n",
    "    day_obj = driver.find_elements_by_xpath('//span[@class=\"fixture__date\"]')\n",
    "    for i in range(len(month_obj)):\n",
    "        date.append(str(day_obj[i].text)+'-'+str(month_obj[i].text).lower())\n",
    "except NoSuchElementException:\n",
    "    date.append('-')\n",
    "    \n",
    "    \n",
    "# Time of match  \n",
    "\n",
    "try :\n",
    "    time_obj = driver.find_elements_by_xpath('//span[@class=\"fixture__time\"]')\n",
    "    \n",
    "    for i in range(len(time_obj)):\n",
    "        time.append(str(time_obj[i].text))\n",
    "except NoSuchElementException:\n",
    "    time.append('-')\n",
    "\n",
    "    \n",
    "#series details and Match Tittle\n",
    "\n",
    "try :\n",
    "    series_obj = driver.find_elements_by_xpath('//span[@class=\"u-unskewed-text fixture__format\"]')\n",
    "    title_obj = driver.find_elements_by_xpath('//span[@class=\"u-unskewed-text fixture__tournament-label u-truncated\"]')\n",
    "    for i in range(len(month_obj)):\n",
    "        series.append(str(series_obj[i].text)+' '+str(title_obj[i].text))\n",
    "        match_title.append(str(title_obj[i].text))\n",
    "except NoSuchElementException:\n",
    "    series.append('-')\n",
    "\n",
    "    \n",
    "# Location of MAtch, and series information\n",
    "\n",
    "try :\n",
    "    location_obj = driver.find_elements_by_xpath('//p[@class=\"fixture__additional-info\"]/span')\n",
    "    match_name_obj = driver.find_elements_by_xpath('//strong[@class=\"fixture__name fixture__name--with-margin\"]')\n",
    "    for i in range(len(time_obj)):\n",
    "        place.append(str(location_obj[i].text))\n",
    "        match_details.append(match_name_obj[i].text)\n",
    "except NoSuchElementException:\n",
    "    place.append ('-')\n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the dictionary of the elements\n",
    "dict= {\n",
    "    'Date':date,'Time':time,'Series':series,'Match': match_title,'Match Location':place,\n",
    "    'series details': match_details\n",
    "}\n",
    "\n",
    "#table creating with creating a DataFrame\n",
    "table = pd.DataFrame(dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>Series</th>\n",
       "      <th>Match</th>\n",
       "      <th>Match Location</th>\n",
       "      <th>series details</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18-july</td>\n",
       "      <td>15:00 IST</td>\n",
       "      <td>ODI SRI LANKA V INDIA 2021</td>\n",
       "      <td>SRI LANKA V INDIA 2021</td>\n",
       "      <td>R Premadasa Stadium, Colombo</td>\n",
       "      <td>1st ODI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20-july</td>\n",
       "      <td>15:00 IST</td>\n",
       "      <td>ODI SRI LANKA V INDIA 2021</td>\n",
       "      <td>SRI LANKA V INDIA 2021</td>\n",
       "      <td>R Premadasa Stadium, Colombo</td>\n",
       "      <td>2nd ODI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23-july</td>\n",
       "      <td>15:00 IST</td>\n",
       "      <td>ODI SRI LANKA V INDIA 2021</td>\n",
       "      <td>SRI LANKA V INDIA 2021</td>\n",
       "      <td>R Premadasa Stadium, Colombo</td>\n",
       "      <td>3rd ODI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25-july</td>\n",
       "      <td>20:00 IST</td>\n",
       "      <td>T20I SRI LANKA V INDIA 2021</td>\n",
       "      <td>SRI LANKA V INDIA 2021</td>\n",
       "      <td>R Premadasa Stadium, Colombo</td>\n",
       "      <td>1st T20I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27-july</td>\n",
       "      <td>20:00 IST</td>\n",
       "      <td>T20I SRI LANKA V INDIA 2021</td>\n",
       "      <td>SRI LANKA V INDIA 2021</td>\n",
       "      <td>R Premadasa Stadium, Colombo</td>\n",
       "      <td>2nd T20I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>29-july</td>\n",
       "      <td>20:00 IST</td>\n",
       "      <td>T20I SRI LANKA V INDIA 2021</td>\n",
       "      <td>SRI LANKA V INDIA 2021</td>\n",
       "      <td>R Premadasa Stadium, Colombo</td>\n",
       "      <td>3rd T20I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>04-august</td>\n",
       "      <td>15:30 IST</td>\n",
       "      <td>TEST ENGLAND V INDIA 2021</td>\n",
       "      <td>ENGLAND V INDIA 2021</td>\n",
       "      <td>Trent Bridge, Nottingham</td>\n",
       "      <td>1st Test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>12-august</td>\n",
       "      <td>15:30 IST</td>\n",
       "      <td>TEST ENGLAND V INDIA 2021</td>\n",
       "      <td>ENGLAND V INDIA 2021</td>\n",
       "      <td>Lord's, London</td>\n",
       "      <td>2nd Test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>25-august</td>\n",
       "      <td>15:30 IST</td>\n",
       "      <td>TEST ENGLAND V INDIA 2021</td>\n",
       "      <td>ENGLAND V INDIA 2021</td>\n",
       "      <td>Headingley, Leeds</td>\n",
       "      <td>3rd Test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>02-september</td>\n",
       "      <td>15:30 IST</td>\n",
       "      <td>TEST ENGLAND V INDIA 2021</td>\n",
       "      <td>ENGLAND V INDIA 2021</td>\n",
       "      <td>The Oval, London</td>\n",
       "      <td>4th Test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10-september</td>\n",
       "      <td>15:30 IST</td>\n",
       "      <td>TEST ENGLAND V INDIA 2021</td>\n",
       "      <td>ENGLAND V INDIA 2021</td>\n",
       "      <td>Old Trafford, Manchester</td>\n",
       "      <td>5th Test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date       Time                       Series  \\\n",
       "0        18-july  15:00 IST   ODI SRI LANKA V INDIA 2021   \n",
       "1        20-july  15:00 IST   ODI SRI LANKA V INDIA 2021   \n",
       "2        23-july  15:00 IST   ODI SRI LANKA V INDIA 2021   \n",
       "3        25-july  20:00 IST  T20I SRI LANKA V INDIA 2021   \n",
       "4        27-july  20:00 IST  T20I SRI LANKA V INDIA 2021   \n",
       "5        29-july  20:00 IST  T20I SRI LANKA V INDIA 2021   \n",
       "6      04-august  15:30 IST    TEST ENGLAND V INDIA 2021   \n",
       "7      12-august  15:30 IST    TEST ENGLAND V INDIA 2021   \n",
       "8      25-august  15:30 IST    TEST ENGLAND V INDIA 2021   \n",
       "9   02-september  15:30 IST    TEST ENGLAND V INDIA 2021   \n",
       "10  10-september  15:30 IST    TEST ENGLAND V INDIA 2021   \n",
       "\n",
       "                     Match                Match Location series details  \n",
       "0   SRI LANKA V INDIA 2021  R Premadasa Stadium, Colombo        1st ODI  \n",
       "1   SRI LANKA V INDIA 2021  R Premadasa Stadium, Colombo        2nd ODI  \n",
       "2   SRI LANKA V INDIA 2021  R Premadasa Stadium, Colombo        3rd ODI  \n",
       "3   SRI LANKA V INDIA 2021  R Premadasa Stadium, Colombo       1st T20I  \n",
       "4   SRI LANKA V INDIA 2021  R Premadasa Stadium, Colombo       2nd T20I  \n",
       "5   SRI LANKA V INDIA 2021  R Premadasa Stadium, Colombo       3rd T20I  \n",
       "6     ENGLAND V INDIA 2021      Trent Bridge, Nottingham       1st Test  \n",
       "7     ENGLAND V INDIA 2021                Lord's, London       2nd Test  \n",
       "8     ENGLAND V INDIA 2021             Headingley, Leeds       3rd Test  \n",
       "9     ENGLAND V INDIA 2021              The Oval, London       4th Test  \n",
       "10    ENGLAND V INDIA 2021      Old Trafford, Manchester       5th Test  "
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape the details of selenium exception from guru99.com.\n",
    "Url = https://www.guru99.com/\n",
    "You need to find following details:\n",
    "A) Name\n",
    "B) Description\n",
    "Note: - From guru99 home page you have to reach to selenium exception handling page through code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading guru99 in web browser\n",
    "\n",
    "driver.get('https://www.guru99.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clicking on Selenium tutorial\n",
    "\n",
    "driver.find_element_by_xpath(\"//div[@class='srch']/span[8]/a\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding the link of Selenium Common Exceptions list and gettting its url and loading it to the web browser\n",
    "\n",
    "exception_link = driver.find_element_by_xpath(\"/html/body/div[2]/section[3]/div/div[1]/main/div/div/div/div/div/div/div[2]/table[5]/tbody/tr[34]/td[1]/a\")\n",
    "\n",
    "driver.get(exception_link.get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All datas are available in table format , no missing vlaues to cause exceptions.\n",
    "\n",
    "row_obj = driver.find_elements_by_xpath('//*[@id=\"g-mainbar\"]/div/div/div/div/div/div/div[2]/table/tbody/tr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = []\n",
    "details = []\n",
    "for i in row_obj[1:]:\n",
    "    \n",
    "    # Splitting the Row as -> each data(each elemeny in loop) contains name and details together.\n",
    "    \n",
    "    exception_name = i.text.split(' ')[0]\n",
    "    \n",
    "    #Splitting the data with exception name as without exception name , else is details parts.\n",
    "    \n",
    "    exception_desc = i.text.split(exception_name)[1]\n",
    "    name.append(exception_name)\n",
    "    details.append(exception_desc)\n",
    "    \n",
    "#Creating a dataFrame of exceptions name and exception Details.\n",
    "table = pd.DataFrame({'Exception_Name':name,'Exception_details':details})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Exception_Name</th>\n",
       "      <th>Exception_details</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ElementNotVisibleException</td>\n",
       "      <td>This type of Selenium exception occurs when a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ElementNotSelectableException</td>\n",
       "      <td>This Selenium exception occurs when an elemen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NoSuchElementException</td>\n",
       "      <td>This Exception occurs if an element could not...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NoSuchFrameException</td>\n",
       "      <td>This Exception occurs if the frame target to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NoAlertPresentException</td>\n",
       "      <td>This Exception occurs when you switch to no p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NoSuchWindowException</td>\n",
       "      <td>This Exception occurs if the window target to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>StaleElementReferenceException</td>\n",
       "      <td>This Selenium exception occurs happens when t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SessionNotFoundException</td>\n",
       "      <td>The WebDriver is acting after you quit the br...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>TimeoutException</td>\n",
       "      <td>Thrown when there is not enough time for a co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>WebDriverException</td>\n",
       "      <td>This Exception takes place when the WebDriver...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ConnectionClosedException</td>\n",
       "      <td>This type of Exception takes place when there...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ElementClickInterceptedException</td>\n",
       "      <td>The command may not be completed as the eleme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ElementNotInteractableException</td>\n",
       "      <td>This Selenium exception is thrown when any el...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ErrorInResponseException</td>\n",
       "      <td>This happens while interacting with the Firef...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ErrorHandler.UnknownServerException</td>\n",
       "      <td>Exception is used as a placeholder in case if...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ImeActivationFailedException</td>\n",
       "      <td>This expectation will occur when IME engine a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ImeNotAvailableException</td>\n",
       "      <td>It takes place when IME support is unavailable.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>InsecureCertificateException</td>\n",
       "      <td>Navigation made the user agent to hit a certi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>InvalidArgumentException</td>\n",
       "      <td>It occurs when an argument does not belong to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>InvalidCookieDomainException</td>\n",
       "      <td>This happens when you try to add a cookie und...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>InvalidCoordinatesException</td>\n",
       "      <td>This type of Exception matches an interacting...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>InvalidElementStateExceptio</td>\n",
       "      <td>It occurs when command can't be finished when...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>InvalidSessionIdException</td>\n",
       "      <td>This Exception took place when the given sess...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>InvalidSwitchToTargetException</td>\n",
       "      <td>This occurs when the frame or window target t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>JavascriptException</td>\n",
       "      <td>This issue occurs while executing JavaScript ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>JsonException</td>\n",
       "      <td>It occurs when you afford to get the session ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>NoSuchAttributeException</td>\n",
       "      <td>This kind of Exception occurs when the attrib...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>MoveTargetOutOfBoundsException</td>\n",
       "      <td>It takes place if the target provided to the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>NoSuchContextException</td>\n",
       "      <td>ContextAware does mobile device testing.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>NoSuchCookieException</td>\n",
       "      <td>This Exception occurs when no cookie matching...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>NotFoundException</td>\n",
       "      <td>This Exception is a subclass of WebDriverExce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>RemoteDriverServerException</td>\n",
       "      <td>This Selenium exception is thrown when the se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>ScreenshotException</td>\n",
       "      <td>It is not possible to capture a screen.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>SessionNotCreatedException</td>\n",
       "      <td>It happens when a new session could not be su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>UnableToSetCookieException</td>\n",
       "      <td>This occurs if a driver is unable to set a co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>UnexpectedTagNameException</td>\n",
       "      <td>Happens if a support class did not get a web ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>UnhandledAlertException</td>\n",
       "      <td>This expectation occurs when there is an aler...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>UnexpectedAlertPresentException</td>\n",
       "      <td>It occurs when there is the appearance of an ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>UnknownMethodException</td>\n",
       "      <td>This Exception happens when the requested com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>UnreachableBrowserException</td>\n",
       "      <td>This Exception occurs only when the browser i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>UnsupportedCommandException</td>\n",
       "      <td>This occurs when remote WebDriver does n't se...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Exception_Name  \\\n",
       "0            ElementNotVisibleException   \n",
       "1         ElementNotSelectableException   \n",
       "2                NoSuchElementException   \n",
       "3                  NoSuchFrameException   \n",
       "4               NoAlertPresentException   \n",
       "5                 NoSuchWindowException   \n",
       "6        StaleElementReferenceException   \n",
       "7              SessionNotFoundException   \n",
       "8                      TimeoutException   \n",
       "9                    WebDriverException   \n",
       "10            ConnectionClosedException   \n",
       "11     ElementClickInterceptedException   \n",
       "12      ElementNotInteractableException   \n",
       "13             ErrorInResponseException   \n",
       "14  ErrorHandler.UnknownServerException   \n",
       "15         ImeActivationFailedException   \n",
       "16             ImeNotAvailableException   \n",
       "17         InsecureCertificateException   \n",
       "18             InvalidArgumentException   \n",
       "19         InvalidCookieDomainException   \n",
       "20          InvalidCoordinatesException   \n",
       "21          InvalidElementStateExceptio   \n",
       "22            InvalidSessionIdException   \n",
       "23       InvalidSwitchToTargetException   \n",
       "24                  JavascriptException   \n",
       "25                        JsonException   \n",
       "26             NoSuchAttributeException   \n",
       "27       MoveTargetOutOfBoundsException   \n",
       "28               NoSuchContextException   \n",
       "29                NoSuchCookieException   \n",
       "30                    NotFoundException   \n",
       "31          RemoteDriverServerException   \n",
       "32                  ScreenshotException   \n",
       "33           SessionNotCreatedException   \n",
       "34           UnableToSetCookieException   \n",
       "35           UnexpectedTagNameException   \n",
       "36              UnhandledAlertException   \n",
       "37      UnexpectedAlertPresentException   \n",
       "38               UnknownMethodException   \n",
       "39          UnreachableBrowserException   \n",
       "40          UnsupportedCommandException   \n",
       "\n",
       "                                    Exception_details  \n",
       "0    This type of Selenium exception occurs when a...  \n",
       "1    This Selenium exception occurs when an elemen...  \n",
       "2    This Exception occurs if an element could not...  \n",
       "3    This Exception occurs if the frame target to ...  \n",
       "4    This Exception occurs when you switch to no p...  \n",
       "5    This Exception occurs if the window target to...  \n",
       "6    This Selenium exception occurs happens when t...  \n",
       "7    The WebDriver is acting after you quit the br...  \n",
       "8    Thrown when there is not enough time for a co...  \n",
       "9    This Exception takes place when the WebDriver...  \n",
       "10   This type of Exception takes place when there...  \n",
       "11   The command may not be completed as the eleme...  \n",
       "12   This Selenium exception is thrown when any el...  \n",
       "13   This happens while interacting with the Firef...  \n",
       "14   Exception is used as a placeholder in case if...  \n",
       "15   This expectation will occur when IME engine a...  \n",
       "16    It takes place when IME support is unavailable.  \n",
       "17   Navigation made the user agent to hit a certi...  \n",
       "18   It occurs when an argument does not belong to...  \n",
       "19   This happens when you try to add a cookie und...  \n",
       "20   This type of Exception matches an interacting...  \n",
       "21   It occurs when command can't be finished when...  \n",
       "22   This Exception took place when the given sess...  \n",
       "23   This occurs when the frame or window target t...  \n",
       "24   This issue occurs while executing JavaScript ...  \n",
       "25   It occurs when you afford to get the session ...  \n",
       "26   This kind of Exception occurs when the attrib...  \n",
       "27   It takes place if the target provided to the ...  \n",
       "28           ContextAware does mobile device testing.  \n",
       "29   This Exception occurs when no cookie matching...  \n",
       "30   This Exception is a subclass of WebDriverExce...  \n",
       "31   This Selenium exception is thrown when the se...  \n",
       "32            It is not possible to capture a screen.  \n",
       "33   It happens when a new session could not be su...  \n",
       "34   This occurs if a driver is unable to set a co...  \n",
       "35   Happens if a support class did not get a web ...  \n",
       "36   This expectation occurs when there is an aler...  \n",
       "37   It occurs when there is the appearance of an ...  \n",
       "38   This Exception happens when the requested com...  \n",
       "39   This Exception occurs only when the browser i...  \n",
       "40   This occurs when remote WebDriver does n't se...  "
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape the details of State-wise GDP of India from statisticstime.com.\n",
    "    Url = http://statisticstimes.com/\n",
    "    You have to find following details:\n",
    "    A) Rank\n",
    "    B) State\n",
    "    C) GSDP at current price (19-20)\n",
    "    D) GSDP at current price (18-19)\n",
    "    E) Share(18-19)\n",
    "    F) GDP($ billion)\n",
    "    Note: - From statisticstimes home page you have to reach to economy page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the url in the browser\n",
    "\n",
    "driver.get('http://statisticstimes.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding the link of Economy of INdia \n",
    "\n",
    "india_economy_page = driver.find_element_by_xpath('/html/body/div[2]/div[1]/div[2]/div[2]/div/a[3]')\n",
    "\n",
    "#extracting the url from the element\n",
    "\n",
    "link  = india_economy_page.get_attribute('href')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "#giving the india economy url to the browser\n",
    "\n",
    "driver.get(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Click the State-wise gdp of india element\n",
    "\n",
    "driver.find_element_by_xpath('/html/body/div[2]/div[2]/div[2]/ul/li[1]/a').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranks = []\n",
    "states = []\n",
    "GSDP_current_price_19_20 = []\n",
    "GSDP_current_price_18_19 = []\n",
    "share_18_19 = []\n",
    "gdp_19 = []\n",
    "\n",
    "    #Rank Element\n",
    "\n",
    "try:\n",
    "    rank_element = driver.find_elements_by_xpath('/html/body/div[3]/div[2]/div[5]/div[1]/div/table/tbody/tr/td[1]')\n",
    "    for i in rank_element:\n",
    "        ranks.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    ranks.append('-')\n",
    "    \n",
    "    #State Element\n",
    "\n",
    "try:\n",
    "    state_element = driver.find_elements_by_xpath('/html/body/div[3]/div[2]/div[5]/div[1]/div/table/tbody/tr/td[2]')\n",
    "    for i in state_element:\n",
    "        states.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    states.append('-')\n",
    "   \n",
    "    \n",
    "    #GSDP 19-20 element\n",
    "\n",
    "try:\n",
    "    GSDP_19_20_element = driver.find_elements_by_xpath('/html/body/div[3]/div[2]/div[5]/div[1]/div/table/tbody/tr/td[3]')\n",
    "    for i in GSDP_19_20_element:\n",
    "        GSDP_current_price_19_20.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    GSDP_current_price_19_20.append('-')\n",
    "    \n",
    "     #GSDP 18-19 element\n",
    "    \n",
    "try:\n",
    "    GSDP_18_19_element = driver.find_elements_by_xpath('/html/body/div[3]/div[2]/div[5]/div[1]/div/table/tbody/tr/td[4]')\n",
    "    for i in GSDP_18_19_element:\n",
    "        GSDP_current_price_18_19.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    GSDP_current_price_18_19.append('-')\n",
    "    \n",
    "    \n",
    "    #share element for 18-19\n",
    "    \n",
    "try:\n",
    "    share_element = driver.find_elements_by_xpath('/html/body/div[3]/div[2]/div[5]/div[1]/div/table/tbody/tr/td[5]')\n",
    "    for i in share_element:\n",
    "        share_18_19.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    share_18_19.append('-')\n",
    "    \n",
    "    \n",
    "    #GDP of 2019\n",
    "    \n",
    "try:\n",
    "    GDP_element = driver.find_elements_by_xpath('/html/body/div[3]/div[2]/div[5]/div[1]/div/table/tbody/tr/td[6]')\n",
    "    for i in GDP_element:\n",
    "        gdp_19.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    gdp_19.append('-')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RANK</th>\n",
       "      <th>STATE</th>\n",
       "      <th>GSDP_19_20</th>\n",
       "      <th>GSDP_18_19</th>\n",
       "      <th>SHARE_PRICE_2019</th>\n",
       "      <th>GDP_in_billions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>-</td>\n",
       "      <td>2,632,792</td>\n",
       "      <td>13.94%</td>\n",
       "      <td>399.921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Tamil Nadu</td>\n",
       "      <td>1,845,853</td>\n",
       "      <td>1,630,208</td>\n",
       "      <td>8.63%</td>\n",
       "      <td>247.629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>1,687,818</td>\n",
       "      <td>1,584,764</td>\n",
       "      <td>8.39%</td>\n",
       "      <td>240.726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Gujarat</td>\n",
       "      <td>-</td>\n",
       "      <td>1,502,899</td>\n",
       "      <td>7.96%</td>\n",
       "      <td>228.290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>1,631,977</td>\n",
       "      <td>1,493,127</td>\n",
       "      <td>7.91%</td>\n",
       "      <td>226.806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>West Bengal</td>\n",
       "      <td>1,253,832</td>\n",
       "      <td>1,089,898</td>\n",
       "      <td>5.77%</td>\n",
       "      <td>165.556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Rajasthan</td>\n",
       "      <td>1,020,989</td>\n",
       "      <td>942,586</td>\n",
       "      <td>4.99%</td>\n",
       "      <td>143.179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>972,782</td>\n",
       "      <td>862,957</td>\n",
       "      <td>4.57%</td>\n",
       "      <td>131.083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Telangana</td>\n",
       "      <td>969,604</td>\n",
       "      <td>861,031</td>\n",
       "      <td>4.56%</td>\n",
       "      <td>130.791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Madhya Pradesh</td>\n",
       "      <td>906,672</td>\n",
       "      <td>809,592</td>\n",
       "      <td>4.29%</td>\n",
       "      <td>122.977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>Kerala</td>\n",
       "      <td>-</td>\n",
       "      <td>781,653</td>\n",
       "      <td>4.14%</td>\n",
       "      <td>118.733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>856,112</td>\n",
       "      <td>774,870</td>\n",
       "      <td>4.10%</td>\n",
       "      <td>117.703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>Haryana</td>\n",
       "      <td>831,610</td>\n",
       "      <td>734,163</td>\n",
       "      <td>3.89%</td>\n",
       "      <td>111.519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>Bihar</td>\n",
       "      <td>611,804</td>\n",
       "      <td>530,363</td>\n",
       "      <td>2.81%</td>\n",
       "      <td>80.562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>Punjab</td>\n",
       "      <td>574,760</td>\n",
       "      <td>526,376</td>\n",
       "      <td>2.79%</td>\n",
       "      <td>79.957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>Odisha</td>\n",
       "      <td>521,275</td>\n",
       "      <td>487,805</td>\n",
       "      <td>2.58%</td>\n",
       "      <td>74.098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>Assam</td>\n",
       "      <td>-</td>\n",
       "      <td>315,881</td>\n",
       "      <td>1.67%</td>\n",
       "      <td>47.982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>Chhattisgarh</td>\n",
       "      <td>329,180</td>\n",
       "      <td>304,063</td>\n",
       "      <td>1.61%</td>\n",
       "      <td>46.187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>Jharkhand</td>\n",
       "      <td>328,598</td>\n",
       "      <td>297,204</td>\n",
       "      <td>1.57%</td>\n",
       "      <td>45.145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>Uttarakhand</td>\n",
       "      <td>-</td>\n",
       "      <td>245,895</td>\n",
       "      <td>1.30%</td>\n",
       "      <td>37.351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>Jammu &amp; Kashmir</td>\n",
       "      <td>-</td>\n",
       "      <td>155,956</td>\n",
       "      <td>0.83%</td>\n",
       "      <td>23.690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>Himachal Pradesh</td>\n",
       "      <td>165,472</td>\n",
       "      <td>153,845</td>\n",
       "      <td>0.81%</td>\n",
       "      <td>23.369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>Goa</td>\n",
       "      <td>80,449</td>\n",
       "      <td>73,170</td>\n",
       "      <td>0.39%</td>\n",
       "      <td>11.115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>Tripura</td>\n",
       "      <td>55,984</td>\n",
       "      <td>49,845</td>\n",
       "      <td>0.26%</td>\n",
       "      <td>7.571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>Chandigarh</td>\n",
       "      <td>-</td>\n",
       "      <td>42,114</td>\n",
       "      <td>0.22%</td>\n",
       "      <td>6.397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>Puducherry</td>\n",
       "      <td>38,253</td>\n",
       "      <td>34,433</td>\n",
       "      <td>0.18%</td>\n",
       "      <td>5.230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>Meghalaya</td>\n",
       "      <td>36,572</td>\n",
       "      <td>33,481</td>\n",
       "      <td>0.18%</td>\n",
       "      <td>5.086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>Sikkim</td>\n",
       "      <td>32,496</td>\n",
       "      <td>28,723</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>4.363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>Manipur</td>\n",
       "      <td>31,790</td>\n",
       "      <td>27,870</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>4.233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>Nagaland</td>\n",
       "      <td>-</td>\n",
       "      <td>27,283</td>\n",
       "      <td>0.14%</td>\n",
       "      <td>4.144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>Arunachal Pradesh</td>\n",
       "      <td>-</td>\n",
       "      <td>24,603</td>\n",
       "      <td>0.13%</td>\n",
       "      <td>3.737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32</td>\n",
       "      <td>Mizoram</td>\n",
       "      <td>26,503</td>\n",
       "      <td>22,287</td>\n",
       "      <td>0.12%</td>\n",
       "      <td>3.385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33</td>\n",
       "      <td>Andaman &amp; Nicobar Islands</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RANK                      STATE GSDP_19_20 GSDP_18_19 SHARE_PRICE_2019  \\\n",
       "0     1                Maharashtra          -  2,632,792           13.94%   \n",
       "1     2                 Tamil Nadu  1,845,853  1,630,208            8.63%   \n",
       "2     3              Uttar Pradesh  1,687,818  1,584,764            8.39%   \n",
       "3     4                    Gujarat          -  1,502,899            7.96%   \n",
       "4     5                  Karnataka  1,631,977  1,493,127            7.91%   \n",
       "5     6                West Bengal  1,253,832  1,089,898            5.77%   \n",
       "6     7                  Rajasthan  1,020,989    942,586            4.99%   \n",
       "7     8             Andhra Pradesh    972,782    862,957            4.57%   \n",
       "8     9                  Telangana    969,604    861,031            4.56%   \n",
       "9    10             Madhya Pradesh    906,672    809,592            4.29%   \n",
       "10   11                     Kerala          -    781,653            4.14%   \n",
       "11   12                      Delhi    856,112    774,870            4.10%   \n",
       "12   13                    Haryana    831,610    734,163            3.89%   \n",
       "13   14                      Bihar    611,804    530,363            2.81%   \n",
       "14   15                     Punjab    574,760    526,376            2.79%   \n",
       "15   16                     Odisha    521,275    487,805            2.58%   \n",
       "16   17                      Assam          -    315,881            1.67%   \n",
       "17   18               Chhattisgarh    329,180    304,063            1.61%   \n",
       "18   19                  Jharkhand    328,598    297,204            1.57%   \n",
       "19   20                Uttarakhand          -    245,895            1.30%   \n",
       "20   21            Jammu & Kashmir          -    155,956            0.83%   \n",
       "21   22           Himachal Pradesh    165,472    153,845            0.81%   \n",
       "22   23                        Goa     80,449     73,170            0.39%   \n",
       "23   24                    Tripura     55,984     49,845            0.26%   \n",
       "24   25                 Chandigarh          -     42,114            0.22%   \n",
       "25   26                 Puducherry     38,253     34,433            0.18%   \n",
       "26   27                  Meghalaya     36,572     33,481            0.18%   \n",
       "27   28                     Sikkim     32,496     28,723            0.15%   \n",
       "28   29                    Manipur     31,790     27,870            0.15%   \n",
       "29   30                   Nagaland          -     27,283            0.14%   \n",
       "30   31          Arunachal Pradesh          -     24,603            0.13%   \n",
       "31   32                    Mizoram     26,503     22,287            0.12%   \n",
       "32   33  Andaman & Nicobar Islands          -          -                -   \n",
       "\n",
       "   GDP_in_billions  \n",
       "0          399.921  \n",
       "1          247.629  \n",
       "2          240.726  \n",
       "3          228.290  \n",
       "4          226.806  \n",
       "5          165.556  \n",
       "6          143.179  \n",
       "7          131.083  \n",
       "8          130.791  \n",
       "9          122.977  \n",
       "10         118.733  \n",
       "11         117.703  \n",
       "12         111.519  \n",
       "13          80.562  \n",
       "14          79.957  \n",
       "15          74.098  \n",
       "16          47.982  \n",
       "17          46.187  \n",
       "18          45.145  \n",
       "19          37.351  \n",
       "20          23.690  \n",
       "21          23.369  \n",
       "22          11.115  \n",
       "23           7.571  \n",
       "24           6.397  \n",
       "25           5.230  \n",
       "26           5.086  \n",
       "27           4.363  \n",
       "28           4.233  \n",
       "29           4.144  \n",
       "30           3.737  \n",
       "31           3.385  \n",
       "32               -  "
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating a Dictionarty of the all the elements\n",
    "\n",
    "dict = {\n",
    "    'RANK':ranks, 'STATE':states,'GSDP_19_20': GSDP_current_price_19_20,'GSDP_18_19':GSDP_current_price_18_19,\n",
    "    'SHARE_PRICE_2019':share_18_19,'GDP_in_billions':gdp_19\n",
    "    }\n",
    "\n",
    "#loading the dictionary to a dataframe \n",
    "table = pd.DataFrame(dict)\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scrape the details of trending repositories on Github.com.\n",
    "    Url = https://github.com/\n",
    "    You have to find the following details:\n",
    "    A) Repository title\n",
    "    B) Repository description\n",
    "    C) Contributors count\n",
    "    D) Language used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading github.com url to the browser\n",
    "\n",
    "driver.get('https://github.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://github.com/trending'"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#find the element of the Trending from the dropdown of the EXPLORE column and extracting the URL of trending\n",
    "\n",
    "link_trending = driver.find_element_by_xpath('/html/body/div[1]/header/div/div[2]/nav/ul/li[4]/details/div/ul[2]/li[3]/a').get_attribute('href')\n",
    "link_trending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feeding the trending url to the browser\n",
    "\n",
    "driver.get(link_trending)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_titles = []\n",
    "\n",
    "repo_urls = []\n",
    "\n",
    "#Extraction Repository Name and its corresponding urls\n",
    "title_element = driver.find_elements_by_xpath('//*[@id=\"js-pjax-container\"]/div[3]/div/div[2]/article/h1/a')\n",
    "for i in title_element:\n",
    "    repo_urls.append(i.get_attribute('href'))\n",
    "    repo_titles.append(i.text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://github.com/chefyuan/algorithm-base',\n",
       " 'https://github.com/trekhleb/javascript-algorithms',\n",
       " 'https://github.com/airbnb/javascript',\n",
       " 'https://github.com/30-seconds/30-seconds-of-code',\n",
       " 'https://github.com/earthly/earthly',\n",
       " 'https://github.com/nvm-sh/nvm',\n",
       " 'https://github.com/microsoft/IoT-For-Beginners',\n",
       " 'https://github.com/bndw/wifi-card',\n",
       " 'https://github.com/austinsonger/Incident-Playbook',\n",
       " 'https://github.com/ryanmcdermott/clean-code-javascript',\n",
       " 'https://github.com/lydiahallie/javascript-questions',\n",
       " 'https://github.com/sorrycc/awesome-javascript',\n",
       " 'https://github.com/jaywcjlove/awesome-mac',\n",
       " 'https://github.com/go-kratos/kratos',\n",
       " 'https://github.com/laynH/Anime-Girls-Holding-Programming-Books',\n",
       " 'https://github.com/swisskyrepo/PayloadsAllTheThings',\n",
       " 'https://github.com/goldbergyoni/nodebestpractices',\n",
       " 'https://github.com/shufflewzc/faker2',\n",
       " 'https://github.com/rosinality/alias-free-gan-pytorch',\n",
       " 'https://github.com/fenixsoft/awesome-fenix',\n",
       " 'https://github.com/mikel-brostrom/Yolov5_DeepSort_Pytorch',\n",
       " 'https://github.com/TheAlphamerc/flutter_ecommerce_app',\n",
       " 'https://github.com/facebook/folly',\n",
       " 'https://github.com/ailabstw/social-distancing-ios',\n",
       " 'https://github.com/Vishal-raj-1/Awesome-JavaScript-Projects']"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ALL REPOSiTORY URLS\n",
    "repo_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_descriptions = []\n",
    "contributors_counts = []\n",
    "language_used  = []\n",
    "\n",
    "#LOOPING THROUGH THE REPOSITORY URLS TO EXTRACT DATA FROM EACH LINK>\n",
    "\n",
    "for  i in repo_urls:\n",
    "    \n",
    "    #loading the repositroy link to the browsetr\n",
    "    driver.get(i)\n",
    "    #waitng for the browser to load and keep the browser to sleep mode for 2 sec\n",
    "    time.sleep(2)\n",
    "    \n",
    "    \n",
    "    #DESCRIPTION OF REPOSITORY\n",
    "    try :\n",
    "        description_element = driver.find_element_by_xpath('//*[@id=\"repo-content-pjax-container\"]/div/div[2]/div[2]/div/div[1]/div/p')\n",
    "        \n",
    "        repo_descriptions.append(description_element.text)\n",
    "    except NoSuchElementException:\n",
    "        repo_descriptions.append('-')\n",
    "\n",
    "    #CONTRIBUTORS_cOUNT\n",
    "    try :\n",
    "        contributors_element = driver.find_element_by_xpath('/html/body/div[4]/div/main/div[2]/div/div/div[2]/div[2]/div/div[5]/div/h2/a/span')\n",
    "       \n",
    "        contributors_counts.append(contributors_element.text)\n",
    "    except NoSuchElementException:\n",
    "        contributors_counts.append('-')\n",
    "\n",
    "    #LANGUAGES used\n",
    "\n",
    "    try :\n",
    "        language_element = driver.find_elements_by_xpath('//*[@id=\"repo-content-pjax-container\"]/div/div[2]/div[2]/div/div[1]/div/div[1]/div/a')\n",
    "        li = []\n",
    "        for i in language_element:\n",
    "           \n",
    "            li.append(i.text)\n",
    "        language_used.append(', '.join(li))\n",
    "    except NoSuchElementException:\n",
    "        language_used.append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Repository_title</th>\n",
       "      <th>Repo_description</th>\n",
       "      <th>Contributors</th>\n",
       "      <th>Languages Used</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>chefyuan / algorithm-base</td>\n",
       "      <td>专门为刚开始刷题的同学准备的算法基地，没有最细只有更细，立志用动画将晦涩难懂的算法说的通俗易懂！</td>\n",
       "      <td>6</td>\n",
       "      <td>java, algorithms, leetcode, offer, interview-p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>trekhleb / javascript-algorithms</td>\n",
       "      <td>📝 Algorithms and data structures implemented i...</td>\n",
       "      <td>14</td>\n",
       "      <td>javascript, computer-science, algorithm, algor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>airbnb / javascript</td>\n",
       "      <td>JavaScript Style Guide</td>\n",
       "      <td>475</td>\n",
       "      <td>javascript, styleguide, eslint, es6, style-lin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30-seconds / 30-seconds-of-code</td>\n",
       "      <td>Short JavaScript code snippets for all your de...</td>\n",
       "      <td>-</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>earthly / earthly</td>\n",
       "      <td>Build automation for the container era</td>\n",
       "      <td>-</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>nvm-sh / nvm</td>\n",
       "      <td>Node Version Manager - POSIX-compliant bash sc...</td>\n",
       "      <td>1.5k</td>\n",
       "      <td>nodejs, shell, bash, zsh, node, install, nvm, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>microsoft / IoT-For-Beginners</td>\n",
       "      <td>12 Weeks, 24 Lessons, IoT for All!</td>\n",
       "      <td>-</td>\n",
       "      <td>python, raspberry-pi, iot, rpi, microcontrolle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>bndw / wifi-card</td>\n",
       "      <td>📶 Print a QR code for connecting to your WiFi</td>\n",
       "      <td>-</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>austinsonger / Incident-Playbook</td>\n",
       "      <td>GOAL: Incident Response Playbooks Mapped to MI...</td>\n",
       "      <td>-</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ryanmcdermott / clean-code-javascript</td>\n",
       "      <td>🛁 Clean Code concepts adapted for JavaScript</td>\n",
       "      <td>109</td>\n",
       "      <td>javascript, best-practices, clean-code, compos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>lydiahallie / javascript-questions</td>\n",
       "      <td>A long list of (advanced) JavaScript questions...</td>\n",
       "      <td>-</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>sorrycc / awesome-javascript</td>\n",
       "      <td>🐢 A collection of awesome browser-side JavaScr...</td>\n",
       "      <td>267</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>jaywcjlove / awesome-mac</td>\n",
       "      <td> Now we have become very big, Different from ...</td>\n",
       "      <td>-</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>go-kratos / kratos</td>\n",
       "      <td>A Go framework for microservices.</td>\n",
       "      <td>103</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>laynH / Anime-Girls-Holding-Programming-Books</td>\n",
       "      <td>Anime Girls Holding Programming Books</td>\n",
       "      <td>-</td>\n",
       "      <td>anime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>swisskyrepo / PayloadsAllTheThings</td>\n",
       "      <td>A list of useful payloads and bypass for Web A...</td>\n",
       "      <td>152</td>\n",
       "      <td>security, hacking, web-application, cheatsheet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>goldbergyoni / nodebestpractices</td>\n",
       "      <td>✅ The Node.js best practices list (June 2021)</td>\n",
       "      <td>-</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>shufflewzc / faker2</td>\n",
       "      <td>不知名大佬备份</td>\n",
       "      <td>-</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>rosinality / alias-free-gan-pytorch</td>\n",
       "      <td>Unofficial implementation of Alias-Free Genera...</td>\n",
       "      <td>2</td>\n",
       "      <td>gan, stylegan2, alias-free-gan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>fenixsoft / awesome-fenix</td>\n",
       "      <td>讨论如何构建一套可靠的大型分布式系统</td>\n",
       "      <td>-</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>mikel-brostrom / Yolov5_DeepSort_Pytorch</td>\n",
       "      <td>Real-time multi-object tracker using YOLO v5 a...</td>\n",
       "      <td>3</td>\n",
       "      <td>real-time, video, pytorch, computer-camera, rt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>TheAlphamerc / flutter_ecommerce_app</td>\n",
       "      <td>E-Commerce App built in flutter</td>\n",
       "      <td>3</td>\n",
       "      <td>flutter, flutter-apps, flutter-demo, flutter-e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>facebook / folly</td>\n",
       "      <td>An open-source C++ library developed and used ...</td>\n",
       "      <td>580</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>ailabstw / social-distancing-ios</td>\n",
       "      <td>Taiwan Social Distancing App - iOS</td>\n",
       "      <td>3</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Vishal-raj-1 / Awesome-JavaScript-Projects</td>\n",
       "      <td>This Repository contain awesome vanilla JavaSc...</td>\n",
       "      <td>-</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Repository_title  \\\n",
       "0                       chefyuan / algorithm-base   \n",
       "1                trekhleb / javascript-algorithms   \n",
       "2                             airbnb / javascript   \n",
       "3                 30-seconds / 30-seconds-of-code   \n",
       "4                               earthly / earthly   \n",
       "5                                    nvm-sh / nvm   \n",
       "6                   microsoft / IoT-For-Beginners   \n",
       "7                                bndw / wifi-card   \n",
       "8                austinsonger / Incident-Playbook   \n",
       "9           ryanmcdermott / clean-code-javascript   \n",
       "10             lydiahallie / javascript-questions   \n",
       "11                   sorrycc / awesome-javascript   \n",
       "12                       jaywcjlove / awesome-mac   \n",
       "13                             go-kratos / kratos   \n",
       "14  laynH / Anime-Girls-Holding-Programming-Books   \n",
       "15             swisskyrepo / PayloadsAllTheThings   \n",
       "16               goldbergyoni / nodebestpractices   \n",
       "17                            shufflewzc / faker2   \n",
       "18            rosinality / alias-free-gan-pytorch   \n",
       "19                      fenixsoft / awesome-fenix   \n",
       "20       mikel-brostrom / Yolov5_DeepSort_Pytorch   \n",
       "21           TheAlphamerc / flutter_ecommerce_app   \n",
       "22                               facebook / folly   \n",
       "23               ailabstw / social-distancing-ios   \n",
       "24     Vishal-raj-1 / Awesome-JavaScript-Projects   \n",
       "\n",
       "                                     Repo_description Contributors  \\\n",
       "0    专门为刚开始刷题的同学准备的算法基地，没有最细只有更细，立志用动画将晦涩难懂的算法说的通俗易懂！            6   \n",
       "1   📝 Algorithms and data structures implemented i...           14   \n",
       "2                              JavaScript Style Guide          475   \n",
       "3   Short JavaScript code snippets for all your de...            -   \n",
       "4              Build automation for the container era            -   \n",
       "5   Node Version Manager - POSIX-compliant bash sc...         1.5k   \n",
       "6                  12 Weeks, 24 Lessons, IoT for All!            -   \n",
       "7       📶 Print a QR code for connecting to your WiFi            -   \n",
       "8   GOAL: Incident Response Playbooks Mapped to MI...            -   \n",
       "9        🛁 Clean Code concepts adapted for JavaScript          109   \n",
       "10  A long list of (advanced) JavaScript questions...            -   \n",
       "11  🐢 A collection of awesome browser-side JavaScr...          267   \n",
       "12   Now we have become very big, Different from ...            -   \n",
       "13                  A Go framework for microservices.          103   \n",
       "14              Anime Girls Holding Programming Books            -   \n",
       "15  A list of useful payloads and bypass for Web A...          152   \n",
       "16      ✅ The Node.js best practices list (June 2021)            -   \n",
       "17                                            不知名大佬备份            -   \n",
       "18  Unofficial implementation of Alias-Free Genera...            2   \n",
       "19                                 讨论如何构建一套可靠的大型分布式系统            -   \n",
       "20  Real-time multi-object tracker using YOLO v5 a...            3   \n",
       "21                    E-Commerce App built in flutter            3   \n",
       "22  An open-source C++ library developed and used ...          580   \n",
       "23                 Taiwan Social Distancing App - iOS            3   \n",
       "24  This Repository contain awesome vanilla JavaSc...            -   \n",
       "\n",
       "                                       Languages Used  \n",
       "0   java, algorithms, leetcode, offer, interview-p...  \n",
       "1   javascript, computer-science, algorithm, algor...  \n",
       "2   javascript, styleguide, eslint, es6, style-lin...  \n",
       "3                                                      \n",
       "4                                                      \n",
       "5   nodejs, shell, bash, zsh, node, install, nvm, ...  \n",
       "6   python, raspberry-pi, iot, rpi, microcontrolle...  \n",
       "7                                                      \n",
       "8                                                      \n",
       "9   javascript, best-practices, clean-code, compos...  \n",
       "10                                                     \n",
       "11                                                     \n",
       "12                                                     \n",
       "13                                                     \n",
       "14                                              anime  \n",
       "15  security, hacking, web-application, cheatsheet...  \n",
       "16                                                     \n",
       "17                                                     \n",
       "18                     gan, stylegan2, alias-free-gan  \n",
       "19                                                     \n",
       "20  real-time, video, pytorch, computer-camera, rt...  \n",
       "21  flutter, flutter-apps, flutter-demo, flutter-e...  \n",
       "22                                                     \n",
       "23                                                     \n",
       "24                                                     "
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating a dictionary of all the elements\n",
    "dict={\n",
    "    'Repository_title': repo_titles,\n",
    "    'Repo_description':repo_descriptions,\n",
    "    'Contributors': contributors_counts,\n",
    "    'Languages Used': language_used,\n",
    "    \n",
    "}\n",
    "\n",
    "#table creation with DATAFRAME\n",
    "table = pd.DataFrame(dict)\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scrape the details of top 100 songs on billboard.com.\n",
    "    Url = https://www.billboard.com/\n",
    "    You have to find the following details:\n",
    "    A) Song name\n",
    "    B) Artist name\n",
    "    C) Last week rank\n",
    "    D) Peak rank\n",
    "    E) Weeks on board\n",
    "    Note: - From the home page you have to click on the charts option then hot 100-page link through code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.billboard.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.billboard.com/charts/hot-100'"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Finding full Xpath of the Hot 100 -> from Charts\n",
    "\n",
    "link = driver.find_element_by_xpath('/html/body/div[2]/div[2]/div[2]/header/div/ul/li[1]/span/span/span/span[1]/ul/li[1]/a').get_attribute('href')\n",
    "link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the extracted link of the hot top 100\n",
    "driver.get(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "song = []\n",
    "artist = []\n",
    "last_week_rank = []\n",
    "peak_rank = []\n",
    "weeks_on_board = []\n",
    "\n",
    "#SONG NAME ELEMENT EXTRACTION\n",
    "try:\n",
    "    song_name_obj = driver.find_elements_by_xpath('//span[@class=\"chart-element__information\"]/span[1]')\n",
    "   \n",
    "    for i in range(len(song_name_obj)):\n",
    "        song.append(song_name_obj[i].text)\n",
    "except NoSuchElementException:\n",
    "    song.append('-')\n",
    "    \n",
    "    \n",
    "#ARTIST NAME ELEMENT EXTRACTION\n",
    "try:\n",
    "   \n",
    "    singer_name_obj = driver.find_elements_by_xpath('//span[@class=\"chart-element__information\"]/span[2]')\n",
    "    for i in range(len(singer_name_obj)):\n",
    "        \n",
    "        artist.append(singer_name_obj[i].text)\n",
    "except NoSuchElementException:\n",
    "    artist.append('-')\n",
    "    \n",
    "    \n",
    "#LAST WEEK RANK of a SONG  ELEMENT EXTRACTION    \n",
    "    #chart-element__metas chart-element__metas--large display--flex flex--y-center\n",
    "try:\n",
    "    rank_lastweek_obj = driver.find_elements_by_xpath('//div[@class=\"chart-element__meta text--center color--secondary text--last\"]')\n",
    "   \n",
    "    for i in range(len(rank_lastweek_obj)):\n",
    "        last_week_rank.append(rank_lastweek_obj[i].text)\n",
    "except NoSuchElementException:\n",
    "    last_week_rank.append('-')\n",
    "    \n",
    "    \n",
    "#PEAK RANK OF A SONG ELEMENT EXTRACTION    \n",
    "try:\n",
    "   \n",
    "    peak_rank_obj = driver.find_elements_by_xpath('//div[@class=\"chart-element__meta text--center color--secondary text--peak\"]')\n",
    "    for i in range(len(peak_rank_obj)):\n",
    "        \n",
    "        peak_rank.append(peak_rank_obj[i].text)\n",
    "except NoSuchElementException:\n",
    "     peak_rank.append('-')  \n",
    "        \n",
    "        \n",
    "#WEEKS ON BOARD for a SONG ELEMENT EXTRACTION\n",
    "try:\n",
    "   \n",
    "    no_of_weeks_onboard_obj = driver.find_elements_by_xpath('//div[@class=\"chart-element__meta text--center color--secondary text--week\"]')\n",
    "    for i in range(len(no_of_weeks_onboard_obj)):\n",
    "        \n",
    "        weeks_on_board.append(no_of_weeks_onboard_obj[i].text)\n",
    "except NoSuchElementException:\n",
    "    weeks_on_board.append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>song_name</th>\n",
       "      <th>artist_name</th>\n",
       "      <th>last_week_rank</th>\n",
       "      <th>peak_rank</th>\n",
       "      <th>no_of_weeks_onboard</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Butter</td>\n",
       "      <td>BTS</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Good 4 U</td>\n",
       "      <td>Olivia Rodrigo</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Levitating</td>\n",
       "      <td>Dua Lipa Featuring DaBaby</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Kiss Me More</td>\n",
       "      <td>Doja Cat Featuring SZA</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Montero (Call Me By Your Name)</td>\n",
       "      <td>Lil Nas X</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>All I Know So Far</td>\n",
       "      <td>P!nk</td>\n",
       "      <td>-</td>\n",
       "      <td>74</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>What's Next</td>\n",
       "      <td>Drake</td>\n",
       "      <td>-</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Enough For You</td>\n",
       "      <td>Olivia Rodrigo</td>\n",
       "      <td>-</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Juggernaut</td>\n",
       "      <td>Tyler, The Creator Featuring Lil Uzi Vert &amp; Ph...</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Tell Em</td>\n",
       "      <td>Cochise &amp; $NOT</td>\n",
       "      <td>-</td>\n",
       "      <td>64</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         song_name  \\\n",
       "0                           Butter   \n",
       "1                         Good 4 U   \n",
       "2                       Levitating   \n",
       "3                     Kiss Me More   \n",
       "4   Montero (Call Me By Your Name)   \n",
       "..                             ...   \n",
       "95               All I Know So Far   \n",
       "96                     What's Next   \n",
       "97                  Enough For You   \n",
       "98                      Juggernaut   \n",
       "99                         Tell Em   \n",
       "\n",
       "                                          artist_name last_week_rank  \\\n",
       "0                                                 BTS              1   \n",
       "1                                      Olivia Rodrigo              2   \n",
       "2                           Dua Lipa Featuring DaBaby              4   \n",
       "3                              Doja Cat Featuring SZA              3   \n",
       "4                                           Lil Nas X              8   \n",
       "..                                                ...            ...   \n",
       "95                                               P!nk              -   \n",
       "96                                              Drake              -   \n",
       "97                                     Olivia Rodrigo              -   \n",
       "98  Tyler, The Creator Featuring Lil Uzi Vert & Ph...             40   \n",
       "99                                     Cochise & $NOT              -   \n",
       "\n",
       "   peak_rank no_of_weeks_onboard  \n",
       "0          1                   7  \n",
       "1          1                   8  \n",
       "2          2                  40  \n",
       "3          3                  13  \n",
       "4          1                  15  \n",
       "..       ...                 ...  \n",
       "95        74                   4  \n",
       "96         1                  16  \n",
       "97        14                   6  \n",
       "98        40                   2  \n",
       "99        64                   4  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict = {\n",
    "    'song_name': song, 'artist_name':artist,\n",
    "    'last_week_rank': last_week_rank,'peak_rank':peak_rank,'no_of_weeks_onboard': weeks_on_board\n",
    "}\n",
    "table = pd.DataFrame(dict)\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scrape the details of Data science recruiters from naukri.com.\n",
    "    Url = https://www.naukri.com/\n",
    "    You have to find the following details:\n",
    "    A) Name\n",
    "    B) Designation\n",
    "    C) Company\n",
    "    D) Skills they hire for\n",
    "    E) Location\n",
    "    Note: - From naukri.com homepage click on the recruiters option and the on the search pane type Data science and\n",
    "    click on search. A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the naukri .com url to the website.\n",
    "driver.get('https://naukri.com')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "#recruitor page link element\n",
    "recruiter_link = driver.find_element_by_xpath('/html/body/div[1]/div[1]/div/ul[1]/li[2]/a').get_attribute('href')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the recruitor link to the browser\n",
    "driver.get(recruiter_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.naukri.com/hr-recruiters-consultants'"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver.current_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "#element of Search tab and seARCH button\n",
    "input_tab = driver.find_element_by_xpath('/html/body/div[2]/div[2]/div[1]/div[1]/form/div[1]/div/div[1]/div[1]/div[2]/input')\n",
    "search_btn = driver.find_element_by_xpath('//button[@class=\"fl qsbSrch blueBtn\"]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sending keys to the Search Tab\n",
    "input_tab.send_keys('Data Science')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "#click the  search element\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting the link elements of the recruitors\n",
    "recruiter_name = driver.find_elements_by_xpath(\"//p[@class='highlightable']/a[1]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Links of all the companies\n",
    "all_recruitment_links = []\n",
    "for i in recruiter_name:\n",
    "    all_recruitment_links.append(i.get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "re_names= []\n",
    "re_company = []\n",
    "re_location = []\n",
    "re_skills = []\n",
    "re_designation = []\n",
    "#lopping through each company to extract data of each company seperately.\n",
    "for i in range(50):\n",
    "    driver.get(all_recruitment_links[i])\n",
    "    time.sleep(2)\n",
    "    \n",
    "    #Recruiter Name\n",
    "    try:\n",
    "        name_element = driver.find_element_by_xpath('/html/body/div[2]/div[1]/div[1]/div[2]/div[2]/h1')\n",
    "        re_names.append(name_element.text)\n",
    "    except NoSuchElementException:\n",
    "        re_names.append('-')\n",
    "        \n",
    "    #Company NAme\n",
    "    try:\n",
    "        company_element = driver.find_element_by_xpath('/html/body/div[2]/div[1]/div[2]/div[2]/div[2]/p[1]')\n",
    "        re_company.append(company_element.text)\n",
    "    except NoSuchElementException:\n",
    "        re_company.append('-')\n",
    "    \n",
    "    #Location element\n",
    "    try:\n",
    "        location_element = driver.find_element_by_xpath('/html/body/div[2]/div[1]/div[1]/div[2]/div[5]/a')\n",
    "       # for i in location_element:\n",
    "        re_location.append(location_element.text)\n",
    "    except NoSuchElementException:\n",
    "        re_location.append('-')\n",
    "        \n",
    "    #Skills\n",
    "    try:\n",
    "        skills_element = driver.find_elements_by_xpath('/html/body/div[2]/div[1]/div[2]/div[2]/div[1]/p')\n",
    "        li = []\n",
    "        for i in skills_element:\n",
    "            li.append(i.text)\n",
    "            \n",
    "        temp = ' '.join(li) \n",
    "        re_skills.append(temp)\n",
    "        \n",
    "    except NoSuchElementException:\n",
    "        re_skills.append('-')\n",
    "      \n",
    "    \n",
    "    #Designation element\n",
    "    try:\n",
    "        designation_element = driver.find_element_by_xpath('/html/body/div[2]/div[1]/div[1]/div[2]/div[3]')\n",
    "        re_designation.append(designation_element.text)\n",
    "    except NoSuchElementException:\n",
    "        re_designation.append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Recruiter_Name</th>\n",
       "      <th>Recruiter_Company</th>\n",
       "      <th>Recruiter_Designation</th>\n",
       "      <th>Skills_needed</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aakash Harit</td>\n",
       "      <td>Data Science Network</td>\n",
       "      <td>HR Manager</td>\n",
       "      <td>Classic ASP Developer , Internet Marketing Pro...</td>\n",
       "      <td>Delhi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>shravan Kumar Gaddam</td>\n",
       "      <td>Shore Infotech India Pvt. Ltd (Since Dec-2016)</td>\n",
       "      <td>Company Recruiter</td>\n",
       "      <td>.Net , Java , Data Science , Linux Administrat...</td>\n",
       "      <td>Hyderabad / Secunderabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MARSIAN Technologies LLP</td>\n",
       "      <td>MARSIAN Technologies LLP (Since Feb-2016)</td>\n",
       "      <td>Company HR</td>\n",
       "      <td>Mid Level, Junior Level</td>\n",
       "      <td>Pune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Anik Agrawal</td>\n",
       "      <td>Enerlytics Software Solutions Pvt Ltd</td>\n",
       "      <td>Company Recruiter</td>\n",
       "      <td>, Mean Stack , javascript , angularjs , mongod...</td>\n",
       "      <td>Ahmedabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>subhas patel</td>\n",
       "      <td>LibraryXProject</td>\n",
       "      <td>Founder &amp; CEO</td>\n",
       "      <td>Hadoop , Spark , Digital Strategy , Data Archi...</td>\n",
       "      <td>UK - (london)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Abhishek - Only Analytics Hiring - India and APAC</td>\n",
       "      <td>Apidel Technologies Division of Transpower (Si...</td>\n",
       "      <td>Recruitment - Lead Consultant</td>\n",
       "      <td>Analytics , Business Intelligence , Business A...</td>\n",
       "      <td>Vadodara / Baroda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Institute for Financial Management and Research</td>\n",
       "      <td>IFMR (Since May-2017)</td>\n",
       "      <td>Programme Manager</td>\n",
       "      <td>Analytics &amp; Business Intelligence</td>\n",
       "      <td>Chennai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Balu Ramesh</td>\n",
       "      <td>Techvantage Systems Pvt Ltd (Since Dec-2014)</td>\n",
       "      <td>HR Administrator</td>\n",
       "      <td>Machine Learning , algorithms , Go Getter , Co...</td>\n",
       "      <td>Trivandrum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Asif Lucknowi</td>\n",
       "      <td>-</td>\n",
       "      <td>Director</td>\n",
       "      <td>Weupskill- Live Wire India</td>\n",
       "      <td>Indore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>InstaFinancials</td>\n",
       "      <td>CBL Data Science Private Limited</td>\n",
       "      <td>Human Resource</td>\n",
       "      <td>Junior Level, Mid Level</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Kalpana Dumpala</td>\n",
       "      <td>Innominds Software (Since Feb-2015)</td>\n",
       "      <td>Executive Hiring</td>\n",
       "      <td>Qa , Ui , ux , Java Developer , Java Architect...</td>\n",
       "      <td>Hyderabad / Secunderabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Mubarak</td>\n",
       "      <td>-</td>\n",
       "      <td>Company HR</td>\n",
       "      <td>MoneyTap</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Kushal Rastogi</td>\n",
       "      <td>-</td>\n",
       "      <td>Company HR</td>\n",
       "      <td>QuantMagnum Technologies Pvt. Ltd.</td>\n",
       "      <td>Mumbai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Ruchi Dhote</td>\n",
       "      <td>Bristlecone India Ltd (Since Apr-2021)</td>\n",
       "      <td>Senior Executive Talent Acquisition</td>\n",
       "      <td>IT Skills</td>\n",
       "      <td>Pune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Mahesh Babu Channa</td>\n",
       "      <td>SocialPrachar.com (Since Jan-2014)</td>\n",
       "      <td>HR Team Lead</td>\n",
       "      <td>Junior Level, Mid Level</td>\n",
       "      <td>Hyderabad / Secunderabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Kapil Devang</td>\n",
       "      <td>BISP Solutions</td>\n",
       "      <td>HR Manager</td>\n",
       "      <td>Big Data , Hadoop , Data Analytics , Data Science</td>\n",
       "      <td>Bhopal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Manisha Yadav</td>\n",
       "      <td>Easi Tax</td>\n",
       "      <td>HR Executive</td>\n",
       "      <td>Mid Level</td>\n",
       "      <td>Navi Mumbai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Riya Rajesh</td>\n",
       "      <td>Novelworx Digital Solutions (Since May-2019)</td>\n",
       "      <td>Manager Talent Acquisition</td>\n",
       "      <td>IT-Software/Software Services</td>\n",
       "      <td>Cochin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Rashmi Bhattacharjee</td>\n",
       "      <td>AXESTRACK SOFTWARE SOLUTIONS PRIVATE LIMITED</td>\n",
       "      <td>HR Head</td>\n",
       "      <td>Mid Level, Top Mangement Level</td>\n",
       "      <td>Delhi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Faizan Kareem</td>\n",
       "      <td>FirstTech Consaltants Pvt.Ltd</td>\n",
       "      <td>HR MANAGER</td>\n",
       "      <td>Data Analytics , Data Science , Machine Learni...</td>\n",
       "      <td>Hyderabad / Secunderabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Rithika dadwal</td>\n",
       "      <td>Affine Analytics</td>\n",
       "      <td>HR Recruiter</td>\n",
       "      <td>Junior Level, Mid Level</td>\n",
       "      <td>Pune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Azahar Shaikh</td>\n",
       "      <td>NEAL ANALYTICS SERVICES PVT LTD</td>\n",
       "      <td>Company Recruiter</td>\n",
       "      <td>Mid Level, High Level</td>\n",
       "      <td>Pune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Sandhya Khandagale</td>\n",
       "      <td>Compumatrice Multimedia Pvt Ltd</td>\n",
       "      <td>HR Recruiter</td>\n",
       "      <td>High Level, Mid Level</td>\n",
       "      <td>Pune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Shaun Rao</td>\n",
       "      <td>Exela Technologies (Since Nov-2014)</td>\n",
       "      <td>Manager - Human Resources</td>\n",
       "      <td>Java , Net , Angularjs , Hr , Infrastructure ,...</td>\n",
       "      <td>Pune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Manas</td>\n",
       "      <td>Autumn Leaf Consulting Services Private Limited</td>\n",
       "      <td>Lead Talent acquisition</td>\n",
       "      <td>High Level, Top Mangement Level</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>kumar</td>\n",
       "      <td>trainin</td>\n",
       "      <td>Proprietor</td>\n",
       "      <td>Data Science , Hadoop , Rpas , Devops , Python...</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Sunil Vedula</td>\n",
       "      <td>Nanoprecise Sci Corp</td>\n",
       "      <td>CEO</td>\n",
       "      <td>Signal Processing , Machine Learning , Neural ...</td>\n",
       "      <td>Others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Rajat Kumar</td>\n",
       "      <td>R.S Consultancy &amp; Services</td>\n",
       "      <td>Founder &amp; CEO</td>\n",
       "      <td>Web Technologies , Project Management , Softwa...</td>\n",
       "      <td>Delhi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Priya Khare</td>\n",
       "      <td>-</td>\n",
       "      <td>Senior Manager</td>\n",
       "      <td>Independent Consultant</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Dhruv Dev Dubey</td>\n",
       "      <td>Confidential (Since Jun-2016)</td>\n",
       "      <td>Company Recruitment Head</td>\n",
       "      <td>S. Finance Manager , Freshers , Experience , S...</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Jayanth N</td>\n",
       "      <td>Dollarbird Information Services Pvt, Ltd (Sinc...</td>\n",
       "      <td>Project Manager</td>\n",
       "      <td>Data Analytics , Managed Services , Team Leading</td>\n",
       "      <td>Mysoru / Mysore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>SREEDHAR</td>\n",
       "      <td>-</td>\n",
       "      <td>Recruitment Consultant</td>\n",
       "      <td>JOBSMILL BUSINESS SOLUTIONS PRIVATE LIMITED</td>\n",
       "      <td>Hyderabad / Secunderabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Radha Manivasagam</td>\n",
       "      <td>Techcovery</td>\n",
       "      <td>HR Executive</td>\n",
       "      <td>Junior Level</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Ravi Dubey</td>\n",
       "      <td>HyrEzy Talent Solutions LLP</td>\n",
       "      <td>Recruitment Manager</td>\n",
       "      <td>Mid Level, Top Mangement Level</td>\n",
       "      <td>Ghaziabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Prateek Kumar</td>\n",
       "      <td>Trisect (Since Jan-2013)</td>\n",
       "      <td>Head</td>\n",
       "      <td>Junior Level</td>\n",
       "      <td>Noida</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Amit Sharma</td>\n",
       "      <td>-</td>\n",
       "      <td>Consultant</td>\n",
       "      <td>ASCO consulting</td>\n",
       "      <td>New Delhi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Kanan</td>\n",
       "      <td>NY INST</td>\n",
       "      <td>senior technology instructor</td>\n",
       "      <td>Mid Level, Junior Level</td>\n",
       "      <td>Chennai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Shashikant Chaudhary</td>\n",
       "      <td>-</td>\n",
       "      <td>HR Recruiter/HR Excutive</td>\n",
       "      <td>3D India Staffing Research &amp; Consulting Co. In...</td>\n",
       "      <td>Aligarh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Brad</td>\n",
       "      <td>O.C. Tanner (Since Jan-2019)</td>\n",
       "      <td>Manager, Technical Recruiting</td>\n",
       "      <td>Junior Level, High Level</td>\n",
       "      <td>Salt Lake City</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Rutuja Pawar</td>\n",
       "      <td>Demand Matrix (Since Feb-2018)</td>\n",
       "      <td>Technical Recruiter</td>\n",
       "      <td>Python , Php , Qa Automation , Ui , Wordpre</td>\n",
       "      <td>Pune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Madhusudhan Sridhar</td>\n",
       "      <td>-</td>\n",
       "      <td>Erp Implementer</td>\n",
       "      <td>MADHUSUDHAN SRIDHAR</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Ankit Sinha</td>\n",
       "      <td>-</td>\n",
       "      <td>Head-Analytics</td>\n",
       "      <td>Suntech Global (Since Feb-2018)</td>\n",
       "      <td>Mumbai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Gaurav Chouhan</td>\n",
       "      <td>Strategic Consulting Lab</td>\n",
       "      <td>Chief Technical Officer</td>\n",
       "      <td>Top Mangement Level, Junior Level</td>\n",
       "      <td>Indore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Rashi Kacker</td>\n",
       "      <td>Impel Labs Pvt. Ltd.</td>\n",
       "      <td>Sr Product Manager</td>\n",
       "      <td>Data Science , Node.js , Angularjs</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Ashwini</td>\n",
       "      <td>-</td>\n",
       "      <td>Director, Global Delivery</td>\n",
       "      <td>MRP Advisers (Since Oct-2017)</td>\n",
       "      <td>MYSORE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Balaji Kolli</td>\n",
       "      <td>-</td>\n",
       "      <td>Co-Founder</td>\n",
       "      <td>Saras Solutions India Pvt Ltd</td>\n",
       "      <td>Hyderabad / Secunderabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Rajani Nagaraj</td>\n",
       "      <td>WildJasmine</td>\n",
       "      <td>HR Manager</td>\n",
       "      <td>java , hadoop , r , Machine Learning , spark ,...</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>ROHIT Kumar</td>\n",
       "      <td>LNT Private Limited (Since Jul-2017)</td>\n",
       "      <td>Architect</td>\n",
       "      <td>Mid Level, High Level</td>\n",
       "      <td>Mumbai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Amir Chowdhury</td>\n",
       "      <td>-</td>\n",
       "      <td>Managing Partner</td>\n",
       "      <td>Granular.ai</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Shailja Mishra</td>\n",
       "      <td>-</td>\n",
       "      <td>HR Manager</td>\n",
       "      <td>Certybox Pvt.Ltd.</td>\n",
       "      <td>Noida</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Recruiter_Name  \\\n",
       "0                                        Aakash Harit   \n",
       "1                                shravan Kumar Gaddam   \n",
       "2                            MARSIAN Technologies LLP   \n",
       "3                                        Anik Agrawal   \n",
       "4                                        subhas patel   \n",
       "5   Abhishek - Only Analytics Hiring - India and APAC   \n",
       "6     Institute for Financial Management and Research   \n",
       "7                                         Balu Ramesh   \n",
       "8                                       Asif Lucknowi   \n",
       "9                                     InstaFinancials   \n",
       "10                                    Kalpana Dumpala   \n",
       "11                                            Mubarak   \n",
       "12                                     Kushal Rastogi   \n",
       "13                                        Ruchi Dhote   \n",
       "14                                 Mahesh Babu Channa   \n",
       "15                                       Kapil Devang   \n",
       "16                                      Manisha Yadav   \n",
       "17                                        Riya Rajesh   \n",
       "18                               Rashmi Bhattacharjee   \n",
       "19                                      Faizan Kareem   \n",
       "20                                     Rithika dadwal   \n",
       "21                                      Azahar Shaikh   \n",
       "22                                 Sandhya Khandagale   \n",
       "23                                          Shaun Rao   \n",
       "24                                              Manas   \n",
       "25                                              kumar   \n",
       "26                                       Sunil Vedula   \n",
       "27                                        Rajat Kumar   \n",
       "28                                        Priya Khare   \n",
       "29                                    Dhruv Dev Dubey   \n",
       "30                                          Jayanth N   \n",
       "31                                           SREEDHAR   \n",
       "32                                  Radha Manivasagam   \n",
       "33                                         Ravi Dubey   \n",
       "34                                      Prateek Kumar   \n",
       "35                                        Amit Sharma   \n",
       "36                                              Kanan   \n",
       "37                               Shashikant Chaudhary   \n",
       "38                                               Brad   \n",
       "39                                       Rutuja Pawar   \n",
       "40                                Madhusudhan Sridhar   \n",
       "41                                        Ankit Sinha   \n",
       "42                                     Gaurav Chouhan   \n",
       "43                                       Rashi Kacker   \n",
       "44                                            Ashwini   \n",
       "45                                       Balaji Kolli   \n",
       "46                                     Rajani Nagaraj   \n",
       "47                                        ROHIT Kumar   \n",
       "48                                     Amir Chowdhury   \n",
       "49                                     Shailja Mishra   \n",
       "\n",
       "                                    Recruiter_Company  \\\n",
       "0                                Data Science Network   \n",
       "1      Shore Infotech India Pvt. Ltd (Since Dec-2016)   \n",
       "2           MARSIAN Technologies LLP (Since Feb-2016)   \n",
       "3               Enerlytics Software Solutions Pvt Ltd   \n",
       "4                                     LibraryXProject   \n",
       "5   Apidel Technologies Division of Transpower (Si...   \n",
       "6                               IFMR (Since May-2017)   \n",
       "7        Techvantage Systems Pvt Ltd (Since Dec-2014)   \n",
       "8                                                   -   \n",
       "9                    CBL Data Science Private Limited   \n",
       "10                Innominds Software (Since Feb-2015)   \n",
       "11                                                  -   \n",
       "12                                                  -   \n",
       "13             Bristlecone India Ltd (Since Apr-2021)   \n",
       "14                 SocialPrachar.com (Since Jan-2014)   \n",
       "15                                     BISP Solutions   \n",
       "16                                           Easi Tax   \n",
       "17       Novelworx Digital Solutions (Since May-2019)   \n",
       "18       AXESTRACK SOFTWARE SOLUTIONS PRIVATE LIMITED   \n",
       "19                      FirstTech Consaltants Pvt.Ltd   \n",
       "20                                   Affine Analytics   \n",
       "21                    NEAL ANALYTICS SERVICES PVT LTD   \n",
       "22                    Compumatrice Multimedia Pvt Ltd   \n",
       "23                Exela Technologies (Since Nov-2014)   \n",
       "24    Autumn Leaf Consulting Services Private Limited   \n",
       "25                                            trainin   \n",
       "26                               Nanoprecise Sci Corp   \n",
       "27                         R.S Consultancy & Services   \n",
       "28                                                  -   \n",
       "29                      Confidential (Since Jun-2016)   \n",
       "30  Dollarbird Information Services Pvt, Ltd (Sinc...   \n",
       "31                                                  -   \n",
       "32                                         Techcovery   \n",
       "33                        HyrEzy Talent Solutions LLP   \n",
       "34                           Trisect (Since Jan-2013)   \n",
       "35                                                  -   \n",
       "36                                            NY INST   \n",
       "37                                                  -   \n",
       "38                       O.C. Tanner (Since Jan-2019)   \n",
       "39                     Demand Matrix (Since Feb-2018)   \n",
       "40                                                  -   \n",
       "41                                                  -   \n",
       "42                           Strategic Consulting Lab   \n",
       "43                               Impel Labs Pvt. Ltd.   \n",
       "44                                                  -   \n",
       "45                                                  -   \n",
       "46                                        WildJasmine   \n",
       "47               LNT Private Limited (Since Jul-2017)   \n",
       "48                                                  -   \n",
       "49                                                  -   \n",
       "\n",
       "                  Recruiter_Designation  \\\n",
       "0                            HR Manager   \n",
       "1                     Company Recruiter   \n",
       "2                            Company HR   \n",
       "3                     Company Recruiter   \n",
       "4                         Founder & CEO   \n",
       "5         Recruitment - Lead Consultant   \n",
       "6                     Programme Manager   \n",
       "7                      HR Administrator   \n",
       "8                              Director   \n",
       "9                        Human Resource   \n",
       "10                     Executive Hiring   \n",
       "11                           Company HR   \n",
       "12                           Company HR   \n",
       "13  Senior Executive Talent Acquisition   \n",
       "14                         HR Team Lead   \n",
       "15                           HR Manager   \n",
       "16                         HR Executive   \n",
       "17           Manager Talent Acquisition   \n",
       "18                              HR Head   \n",
       "19                           HR MANAGER   \n",
       "20                         HR Recruiter   \n",
       "21                    Company Recruiter   \n",
       "22                         HR Recruiter   \n",
       "23            Manager - Human Resources   \n",
       "24              Lead Talent acquisition   \n",
       "25                           Proprietor   \n",
       "26                                  CEO   \n",
       "27                        Founder & CEO   \n",
       "28                       Senior Manager   \n",
       "29             Company Recruitment Head   \n",
       "30                      Project Manager   \n",
       "31               Recruitment Consultant   \n",
       "32                         HR Executive   \n",
       "33                  Recruitment Manager   \n",
       "34                                 Head   \n",
       "35                           Consultant   \n",
       "36         senior technology instructor   \n",
       "37             HR Recruiter/HR Excutive   \n",
       "38        Manager, Technical Recruiting   \n",
       "39                  Technical Recruiter   \n",
       "40                      Erp Implementer   \n",
       "41                       Head-Analytics   \n",
       "42              Chief Technical Officer   \n",
       "43                   Sr Product Manager   \n",
       "44            Director, Global Delivery   \n",
       "45                           Co-Founder   \n",
       "46                           HR Manager   \n",
       "47                            Architect   \n",
       "48                     Managing Partner   \n",
       "49                           HR Manager   \n",
       "\n",
       "                                        Skills_needed  \\\n",
       "0   Classic ASP Developer , Internet Marketing Pro...   \n",
       "1   .Net , Java , Data Science , Linux Administrat...   \n",
       "2                           Mid Level, Junior Level     \n",
       "3   , Mean Stack , javascript , angularjs , mongod...   \n",
       "4   Hadoop , Spark , Digital Strategy , Data Archi...   \n",
       "5   Analytics , Business Intelligence , Business A...   \n",
       "6                   Analytics & Business Intelligence   \n",
       "7   Machine Learning , algorithms , Go Getter , Co...   \n",
       "8                        Weupskill- Live Wire India     \n",
       "9                           Junior Level, Mid Level     \n",
       "10  Qa , Ui , ux , Java Developer , Java Architect...   \n",
       "11                                         MoneyTap     \n",
       "12               QuantMagnum Technologies Pvt. Ltd.     \n",
       "13                                        IT Skills     \n",
       "14                          Junior Level, Mid Level     \n",
       "15  Big Data , Hadoop , Data Analytics , Data Science   \n",
       "16                                        Mid Level     \n",
       "17                      IT-Software/Software Services   \n",
       "18                   Mid Level, Top Mangement Level     \n",
       "19  Data Analytics , Data Science , Machine Learni...   \n",
       "20                           Junior Level, Mid Level    \n",
       "21                            Mid Level, High Level     \n",
       "22                              High Level, Mid Level   \n",
       "23  Java , Net , Angularjs , Hr , Infrastructure ,...   \n",
       "24                  High Level, Top Mangement Level     \n",
       "25  Data Science , Hadoop , Rpas , Devops , Python...   \n",
       "26  Signal Processing , Machine Learning , Neural ...   \n",
       "27  Web Technologies , Project Management , Softwa...   \n",
       "28                           Independent Consultant     \n",
       "29  S. Finance Manager , Freshers , Experience , S...   \n",
       "30   Data Analytics , Managed Services , Team Leading   \n",
       "31      JOBSMILL BUSINESS SOLUTIONS PRIVATE LIMITED     \n",
       "32                                     Junior Level     \n",
       "33                  Mid Level, Top Mangement Level      \n",
       "34                                     Junior Level     \n",
       "35                                  ASCO consulting     \n",
       "36                          Mid Level, Junior Level     \n",
       "37  3D India Staffing Research & Consulting Co. In...   \n",
       "38                        Junior Level, High Level      \n",
       "39     Python , Php , Qa Automation , Ui , Wordpre      \n",
       "40                              MADHUSUDHAN SRIDHAR     \n",
       "41                  Suntech Global (Since Feb-2018)     \n",
       "42                Top Mangement Level, Junior Level     \n",
       "43               Data Science , Node.js , Angularjs     \n",
       "44                    MRP Advisers (Since Oct-2017)     \n",
       "45                    Saras Solutions India Pvt Ltd     \n",
       "46  java , hadoop , r , Machine Learning , spark ,...   \n",
       "47                            Mid Level, High Level     \n",
       "48                                      Granular.ai     \n",
       "49                                Certybox Pvt.Ltd.     \n",
       "\n",
       "                    Location  \n",
       "0                      Delhi  \n",
       "1   Hyderabad / Secunderabad  \n",
       "2                       Pune  \n",
       "3                  Ahmedabad  \n",
       "4              UK - (london)  \n",
       "5          Vadodara / Baroda  \n",
       "6                    Chennai  \n",
       "7                 Trivandrum  \n",
       "8                     Indore  \n",
       "9      Bengaluru / Bangalore  \n",
       "10  Hyderabad / Secunderabad  \n",
       "11     Bengaluru / Bangalore  \n",
       "12                    Mumbai  \n",
       "13                      Pune  \n",
       "14  Hyderabad / Secunderabad  \n",
       "15                    Bhopal  \n",
       "16               Navi Mumbai  \n",
       "17                    Cochin  \n",
       "18                     Delhi  \n",
       "19  Hyderabad / Secunderabad  \n",
       "20                      Pune  \n",
       "21                      Pune  \n",
       "22                      Pune  \n",
       "23                      Pune  \n",
       "24     Bengaluru / Bangalore  \n",
       "25     Bengaluru / Bangalore  \n",
       "26                    Others  \n",
       "27                     Delhi  \n",
       "28     Bengaluru / Bangalore  \n",
       "29     Bengaluru / Bangalore  \n",
       "30           Mysoru / Mysore  \n",
       "31  Hyderabad / Secunderabad  \n",
       "32     Bengaluru / Bangalore  \n",
       "33                 Ghaziabad  \n",
       "34                     Noida  \n",
       "35                 New Delhi  \n",
       "36                   Chennai  \n",
       "37                   Aligarh  \n",
       "38            Salt Lake City  \n",
       "39                      Pune  \n",
       "40     Bengaluru / Bangalore  \n",
       "41                    Mumbai  \n",
       "42                    Indore  \n",
       "43     Bengaluru / Bangalore  \n",
       "44                    MYSORE  \n",
       "45  Hyderabad / Secunderabad  \n",
       "46     Bengaluru / Bangalore  \n",
       "47                    Mumbai  \n",
       "48                            \n",
       "49                     Noida  "
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating a dictionary of all the elements\n",
    "dict = {\n",
    "    'Recruiter_Name': re_names,'Recruiter_Company':re_company,\n",
    "    'Recruiter_Designation':re_designation,'Skills_needed':re_skills,\n",
    "    'Location':re_location\n",
    "}\n",
    "#creating a DataFrame/ Table of the dictionary\n",
    "table = pd.DataFrame(dict)\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Scrape the details of Highest selling novels.\n",
    "    Url = https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-greycompare/\n",
    "    You have to find the following details:\n",
    "    A) Book name\n",
    "    B) Author name\n",
    "    C) Volumes sold\n",
    "    D) Publisher\n",
    "    E) Genre\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the url to the browser.\n",
    "driver.get('https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating empty list for all the elements\n",
    "book_names = []\n",
    "author_names = []\n",
    "volumes_sold = []\n",
    "publisher = []\n",
    "genre = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "#No need for exception handlnig as the data is in table format and all the data points are available to extract.\n",
    "\n",
    "    #NAME OF BOOK\n",
    "    name_obj = driver.find_elements_by_xpath('//*[@id=\"article-body-blocks\"]/div/table/tbody/tr/td[2]')\n",
    "    for i in name_obj:\n",
    "        book_names.append(i.text)\n",
    "\n",
    "    #AUTHOR NAME\n",
    "    author_obj = driver.find_elements_by_xpath('//*[@id=\"article-body-blocks\"]/div/table/tbody/tr/td[3]')\n",
    "    for i in author_obj:\n",
    "        author_names.append(i.text)\n",
    "\n",
    "        \n",
    "    #VOLUME OF BOOKS SOLD\n",
    "    volume_obj = driver.find_elements_by_xpath('//*[@id=\"article-body-blocks\"]/div/table/tbody/tr/td[4]')\n",
    "    for i in volume_obj:\n",
    "        volumes_sold.append(i.text)\n",
    "\n",
    "    #PUBLISHER NAME\n",
    "    publisher_obj = driver.find_elements_by_xpath('//*[@id=\"article-body-blocks\"]/div/table/tbody/tr/td[5]')\n",
    "    for i in publisher_obj:\n",
    "        publisher.append(i.text)\n",
    "\n",
    "        \n",
    "    #GENRE ELEMENT\n",
    "    genre_obj = driver.find_elements_by_xpath('//*[@id=\"article-body-blocks\"]/div/table/tbody/tr/td[6]')\n",
    "    for i in genre_obj:\n",
    "        genre.append(i.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BOOK_NAME</th>\n",
       "      <th>AUTHOR_NAME</th>\n",
       "      <th>VOLUME_SOLD</th>\n",
       "      <th>PUBLISHER_NAME</th>\n",
       "      <th>GENRE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Da Vinci Code,The</td>\n",
       "      <td>Brown, Dan</td>\n",
       "      <td>5,094,805</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>Action, Adventure, Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Harry Potter and the Deathly Hallows</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,475,152</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Drama, Fantasy, Horror</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,200,654</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Drama, Horror, Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,179,479</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Drama, Mystery, Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fifty Shades of Grey</td>\n",
       "      <td>James, E. L.</td>\n",
       "      <td>3,758,936</td>\n",
       "      <td>Random House</td>\n",
       "      <td>Drama, Mystery, Sci-Fi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Ghost,The</td>\n",
       "      <td>Harris, Robert</td>\n",
       "      <td>807,311</td>\n",
       "      <td>Random House</td>\n",
       "      <td>Drama, Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Happy Days with the Naked Chef</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>794,201</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Adventure, Comedy, Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Hunger Games,The:Hunger Games Trilogy</td>\n",
       "      <td>Collins, Suzanne</td>\n",
       "      <td>792,187</td>\n",
       "      <td>Scholastic Ltd.</td>\n",
       "      <td>Crime, Drama, Mystery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Lost Boy,The:A Foster Child's Search for the L...</td>\n",
       "      <td>Pelzer, Dave</td>\n",
       "      <td>791,507</td>\n",
       "      <td>Orion</td>\n",
       "      <td>Comedy, Crime, Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Jamie's Ministry of Food:Anyone Can Learn to C...</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>791,095</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Drama, Horror, Mystery</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            BOOK_NAME       AUTHOR_NAME  \\\n",
       "0                                   Da Vinci Code,The        Brown, Dan   \n",
       "1                Harry Potter and the Deathly Hallows     Rowling, J.K.   \n",
       "2            Harry Potter and the Philosopher's Stone     Rowling, J.K.   \n",
       "3           Harry Potter and the Order of the Phoenix     Rowling, J.K.   \n",
       "4                                Fifty Shades of Grey      James, E. L.   \n",
       "..                                                ...               ...   \n",
       "95                                          Ghost,The    Harris, Robert   \n",
       "96                     Happy Days with the Naked Chef     Oliver, Jamie   \n",
       "97              Hunger Games,The:Hunger Games Trilogy  Collins, Suzanne   \n",
       "98  Lost Boy,The:A Foster Child's Search for the L...      Pelzer, Dave   \n",
       "99  Jamie's Ministry of Food:Anyone Can Learn to C...     Oliver, Jamie   \n",
       "\n",
       "   VOLUME_SOLD   PUBLISHER_NAME                     GENRE  \n",
       "0    5,094,805       Transworld  Action, Adventure, Drama  \n",
       "1    4,475,152       Bloomsbury    Drama, Fantasy, Horror  \n",
       "2    4,200,654       Bloomsbury   Drama, Horror, Thriller  \n",
       "3    4,179,479       Bloomsbury  Drama, Mystery, Thriller  \n",
       "4    3,758,936     Random House    Drama, Mystery, Sci-Fi  \n",
       "..         ...              ...                       ...  \n",
       "95     807,311     Random House            Drama, Fantasy  \n",
       "96     794,201          Penguin  Adventure, Comedy, Drama  \n",
       "97     792,187  Scholastic Ltd.     Crime, Drama, Mystery  \n",
       "98     791,507            Orion      Comedy, Crime, Drama  \n",
       "99     791,095          Penguin    Drama, Horror, Mystery  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating a dictionary of all the elements\n",
    "dict = {\n",
    "    'BOOK_NAME':book_names,'AUTHOR_NAME':author_names,'VOLUME_SOLD':volumes_sold,\n",
    "    'PUBLISHER_NAME':publisher,'GENRE':genre\n",
    "}\n",
    "#Dataframe/Table creating of the dictionary\n",
    "table = pd.DataFrame(dict)\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scrape the details most watched tv series of all time from imdb.com.\n",
    "        Url = https://www.imdb.com/list/ls095964455/\n",
    "        You have to find the following details:\n",
    "        A) Name\n",
    "        B) Year span\n",
    "        C) Genre\n",
    "        D) Run time\n",
    "        E) Ratings\n",
    "        F) Votes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Laoding the url to the browser\n",
    "driver.get('https://www.imdb.com/list/ls095964455/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = []\n",
    "year_span = []\n",
    "genre = []\n",
    "run_time = []\n",
    "ratings = []\n",
    "votes = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AS all elements are avaialbe, no exception needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "    #MOIVE NAME ELEMENT\n",
    "\n",
    "movie_name_obj = driver.find_elements_by_xpath('//h3[@class=\"lister-item-header\"]/a')\n",
    "for i in movie_name_obj:\n",
    "    movies.append(i.text)\n",
    "\n",
    "        \n",
    "    #YEAR SPAN OBJECT\n",
    "\n",
    "year_span_obj = driver.find_elements_by_xpath('//h3[@class=\"lister-item-header\"]/span[2]')\n",
    "for i in year_span_obj:\n",
    "    year_span.append(i.text)\n",
    "\n",
    "    #GENRE OBJECT\n",
    "\n",
    "genre_obj = driver.find_elements_by_xpath('//span[@class=\"genre\"]')\n",
    "for i in genre_obj:\n",
    "    genre.append(i.text)\n",
    "\n",
    "        \n",
    "    #RUNTIME ELEMENT\n",
    "    \n",
    "runtime_obj = driver.find_elements_by_xpath('//span[@class=\"runtime\"]')\n",
    "for i in runtime_obj:\n",
    "    run_time.append(i.text)\n",
    "\n",
    "    #RATING OBJECT\n",
    "    \n",
    "rating_obj = driver.find_elements_by_xpath('//div[@class=\"ipl-rating-star small\"]/span[2]')\n",
    "for i in rating_obj:\n",
    "    ratings.append(i.text)\n",
    "\n",
    "    #NO OF VOTES OBJECT\n",
    "       \n",
    "votes_obj = driver.find_elements_by_xpath('//*[@id=\"main\"]/div/div[3]/div[3]/div/div[2]/p[4]/span[2]')\n",
    "for i in votes_obj:\n",
    "    votes.append(i.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie</th>\n",
       "      <th>duration time</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Votes</th>\n",
       "      <th>Year_span</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Game of Thrones</td>\n",
       "      <td>57 min</td>\n",
       "      <td>Action, Adventure, Drama</td>\n",
       "      <td>9.2</td>\n",
       "      <td>1,835,393</td>\n",
       "      <td>(2011–2019)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stranger Things</td>\n",
       "      <td>51 min</td>\n",
       "      <td>Drama, Fantasy, Horror</td>\n",
       "      <td>8.7</td>\n",
       "      <td>874,161</td>\n",
       "      <td>(2016– )</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Walking Dead</td>\n",
       "      <td>44 min</td>\n",
       "      <td>Drama, Horror, Thriller</td>\n",
       "      <td>8.2</td>\n",
       "      <td>879,319</td>\n",
       "      <td>(2010–2022)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13 Reasons Why</td>\n",
       "      <td>60 min</td>\n",
       "      <td>Drama, Mystery, Thriller</td>\n",
       "      <td>7.6</td>\n",
       "      <td>264,212</td>\n",
       "      <td>(2017–2020)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The 100</td>\n",
       "      <td>43 min</td>\n",
       "      <td>Drama, Mystery, Sci-Fi</td>\n",
       "      <td>7.6</td>\n",
       "      <td>225,709</td>\n",
       "      <td>(2014–2020)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Reign</td>\n",
       "      <td>42 min</td>\n",
       "      <td>Drama, Fantasy</td>\n",
       "      <td>7.5</td>\n",
       "      <td>44,790</td>\n",
       "      <td>(2013–2017)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>A Series of Unfortunate Events</td>\n",
       "      <td>50 min</td>\n",
       "      <td>Adventure, Comedy, Drama</td>\n",
       "      <td>7.8</td>\n",
       "      <td>55,397</td>\n",
       "      <td>(2017–2019)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Criminal Minds</td>\n",
       "      <td>42 min</td>\n",
       "      <td>Crime, Drama, Mystery</td>\n",
       "      <td>8.1</td>\n",
       "      <td>169,584</td>\n",
       "      <td>(2005–2020)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Scream: The TV Series</td>\n",
       "      <td>45 min</td>\n",
       "      <td>Comedy, Crime, Drama</td>\n",
       "      <td>7.1</td>\n",
       "      <td>35,120</td>\n",
       "      <td>(2015–2019)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>The Haunting of Hill House</td>\n",
       "      <td>572 min</td>\n",
       "      <td>Drama, Horror, Mystery</td>\n",
       "      <td>8.6</td>\n",
       "      <td>193,351</td>\n",
       "      <td>(2018)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             movie duration time                     Genre  \\\n",
       "0                  Game of Thrones        57 min  Action, Adventure, Drama   \n",
       "1                  Stranger Things        51 min    Drama, Fantasy, Horror   \n",
       "2                 The Walking Dead        44 min   Drama, Horror, Thriller   \n",
       "3                   13 Reasons Why        60 min  Drama, Mystery, Thriller   \n",
       "4                          The 100        43 min    Drama, Mystery, Sci-Fi   \n",
       "..                             ...           ...                       ...   \n",
       "95                           Reign        42 min            Drama, Fantasy   \n",
       "96  A Series of Unfortunate Events        50 min  Adventure, Comedy, Drama   \n",
       "97                  Criminal Minds        42 min     Crime, Drama, Mystery   \n",
       "98           Scream: The TV Series        45 min      Comedy, Crime, Drama   \n",
       "99      The Haunting of Hill House       572 min    Drama, Horror, Mystery   \n",
       "\n",
       "   Rating      Votes    Year_span  \n",
       "0     9.2  1,835,393  (2011–2019)  \n",
       "1     8.7    874,161     (2016– )  \n",
       "2     8.2    879,319  (2010–2022)  \n",
       "3     7.6    264,212  (2017–2020)  \n",
       "4     7.6    225,709  (2014–2020)  \n",
       "..    ...        ...          ...  \n",
       "95    7.5     44,790  (2013–2017)  \n",
       "96    7.8     55,397  (2017–2019)  \n",
       "97    8.1    169,584  (2005–2020)  \n",
       "98    7.1     35,120  (2015–2019)  \n",
       "99    8.6    193,351       (2018)  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating a dictionary of all the elements\n",
    "dict = {\n",
    "    'movie':movies,'duration time':run_time,'Genre':genre,\n",
    "    'Rating':ratings,'Votes':votes,'Year_span':year_span\n",
    "}\n",
    "#data frame creation\n",
    "table = pd.DataFrame(dict)\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Details of Datasets from UCI machine learning repositories.\n",
    "     Url = https://archive.ics.uci.edu/\n",
    "     You have to find the following details:\n",
    "    A) Dataset name\n",
    "    B) Data type\n",
    "    C) Task\n",
    "    D) Attribute type\n",
    "    E) No of instances\n",
    "    F) No of attribute\n",
    "    G) Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the url to the browser\n",
    "driver.get('https://archive.ics.uci.edu/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "#repository element element object\n",
    "repository_links = driver.find_elements_by_xpath('//span[@class=\"normal\"]/a')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://archive.ics.uci.edu/ml/index.html\n",
      "http://cml.ics.uci.edu/\n",
      "https://archive.ics.uci.edu/ml/about.html\n",
      "https://archive.ics.uci.edu/ml/citation_policy.html\n",
      "https://archive.ics.uci.edu/ml/donation_policy.html\n",
      "https://archive.ics.uci.edu/ml/contact.html\n",
      "http://archive.ics.uci.edu/ml/noteNetflix.txt\n",
      "https://archive.ics.uci.edu/ml/datasets/Parkinsons\n",
      "https://archive.ics.uci.edu/ml/datasets/Synchronous+Machine+Data+Set\n",
      "https://archive.ics.uci.edu/ml/datasets/Wikipedia+Math+Essentials\n",
      "https://archive.ics.uci.edu/ml/datasets/Wikipedia+Math+Essentials\n",
      "https://archive.ics.uci.edu/ml/datasets/Hungarian+Chickenpox+Cases\n",
      "https://archive.ics.uci.edu/ml/datasets/Myocardial+infarction+complications\n",
      "https://archive.ics.uci.edu/ml/datasets/Gait+Classification\n",
      "https://archive.ics.uci.edu/ml/datasets/Codon+usage\n",
      "https://archive.ics.uci.edu/ml/datasets/in-vehicle+coupon+recommendation\n",
      "https://archive.ics.uci.edu/ml/datasets/Dry+Bean+Dataset\n",
      "https://archive.ics.uci.edu/ml/datasets/Intelligent+Media+Accelerometer+and+Gyroscope+%28IM-AccGyro%29+Dataset\n",
      "https://archive.ics.uci.edu/ml/datasets/AI4I+2020+Predictive+Maintenance+Dataset\n",
      "https://archive.ics.uci.edu/ml/datasets/Wisesight+Sentiment+Corpus\n",
      "https://archive.ics.uci.edu/ml/datasets/Iris\n",
      "https://archive.ics.uci.edu/ml/datasets/Adult\n",
      "https://archive.ics.uci.edu/ml/datasets/Wine\n",
      "https://archive.ics.uci.edu/ml/datasets/Wine+Quality\n",
      "https://archive.ics.uci.edu/ml/datasets/Heart+Disease\n",
      "https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Diagnostic%29\n",
      "https://archive.ics.uci.edu/ml/datasets/Bank+Marketing\n",
      "https://archive.ics.uci.edu/ml/datasets/Car+Evaluation\n",
      "https://archive.ics.uci.edu/ml/datasets/Human+Activity+Recognition+Using+Smartphones\n",
      "https://archive.ics.uci.edu/ml/datasets/Abalone\n",
      "https://archive.ics.uci.edu/ml/datasets/Forest+Fires\n",
      "https://archive.ics.uci.edu/ml/datasets/Student+Performance\n",
      "https://archive.ics.uci.edu/ml/about.html\n",
      "https://archive.ics.uci.edu/ml/citation_policy.html\n",
      "https://archive.ics.uci.edu/ml/donation_policy.html\n",
      "https://archive.ics.uci.edu/ml/contact.html\n",
      "http://cml.ics.uci.edu/\n"
     ]
    }
   ],
   "source": [
    "#al lthe repository element links\n",
    "for i in repository_links:\n",
    "    print(i.get_attribute('href'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### we can see some of the links are not dataset links, we can segregate it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataset URLS\n",
    "urls = []\n",
    "for i in repository_links:\n",
    "    if(i.get_attribute('href').find('datasets')>0):\n",
    "        urls.append(i.get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://archive.ics.uci.edu/ml/datasets/Parkinsons',\n",
       " 'https://archive.ics.uci.edu/ml/datasets/Synchronous+Machine+Data+Set',\n",
       " 'https://archive.ics.uci.edu/ml/datasets/Wikipedia+Math+Essentials',\n",
       " 'https://archive.ics.uci.edu/ml/datasets/Wikipedia+Math+Essentials',\n",
       " 'https://archive.ics.uci.edu/ml/datasets/Hungarian+Chickenpox+Cases',\n",
       " 'https://archive.ics.uci.edu/ml/datasets/Myocardial+infarction+complications',\n",
       " 'https://archive.ics.uci.edu/ml/datasets/Gait+Classification',\n",
       " 'https://archive.ics.uci.edu/ml/datasets/Codon+usage',\n",
       " 'https://archive.ics.uci.edu/ml/datasets/in-vehicle+coupon+recommendation',\n",
       " 'https://archive.ics.uci.edu/ml/datasets/Dry+Bean+Dataset',\n",
       " 'https://archive.ics.uci.edu/ml/datasets/Intelligent+Media+Accelerometer+and+Gyroscope+%28IM-AccGyro%29+Dataset',\n",
       " 'https://archive.ics.uci.edu/ml/datasets/AI4I+2020+Predictive+Maintenance+Dataset',\n",
       " 'https://archive.ics.uci.edu/ml/datasets/Wisesight+Sentiment+Corpus',\n",
       " 'https://archive.ics.uci.edu/ml/datasets/Iris',\n",
       " 'https://archive.ics.uci.edu/ml/datasets/Adult',\n",
       " 'https://archive.ics.uci.edu/ml/datasets/Wine',\n",
       " 'https://archive.ics.uci.edu/ml/datasets/Wine+Quality',\n",
       " 'https://archive.ics.uci.edu/ml/datasets/Heart+Disease',\n",
       " 'https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Diagnostic%29',\n",
       " 'https://archive.ics.uci.edu/ml/datasets/Bank+Marketing',\n",
       " 'https://archive.ics.uci.edu/ml/datasets/Car+Evaluation',\n",
       " 'https://archive.ics.uci.edu/ml/datasets/Human+Activity+Recognition+Using+Smartphones',\n",
       " 'https://archive.ics.uci.edu/ml/datasets/Abalone',\n",
       " 'https://archive.ics.uci.edu/ml/datasets/Forest+Fires',\n",
       " 'https://archive.ics.uci.edu/ml/datasets/Student+Performance']"
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_names = []\n",
    "dataset_datatypes = []\n",
    "tasks = []\n",
    "attribute_types = []\n",
    "no_instances = []\n",
    "no_attributes = []\n",
    "year = []\n",
    "\n",
    "\n",
    "#Looping through the each dataset urls-> \n",
    "\n",
    "for i in urls:\n",
    "    driver.get(i)\n",
    "    \n",
    "    #dataset name\n",
    "    \n",
    "    try:\n",
    "        dataset_name_obj = driver.find_element_by_xpath('//span[@class=\"heading\"]/b')\n",
    "        dataset_names.append(dataset_name_obj.text)\n",
    "    except:\n",
    "        dataset_names.append('-')\n",
    "       \n",
    "    #DATA SET DATA TYPES\n",
    "    try:\n",
    "        dataset_datatype_obj = driver.find_element_by_xpath('/html/body/table[2]/tbody/tr/td/table[2]/tbody/tr[1]/td[2]/p')\n",
    "        dataset_datatypes.append(dataset_datatype_obj.text)\n",
    "    except:\n",
    "        dataset_datatypes.append('-')\n",
    "        \n",
    "    #TASKS  \n",
    "        \n",
    "    try:\n",
    "        dataset_task_obj = driver.find_element_by_xpath('/html/body/table[2]/tbody/tr/td/table[2]/tbody/tr[3]/td[2]/p')\n",
    "        tasks.append(dataset_task_obj.text)\n",
    "    except:\n",
    "        tasks.append('-')\n",
    "      \n",
    "    #ATTRIBUTE TYPES\n",
    "        \n",
    "    try:\n",
    "        dataset_attr_type_obj = driver.find_element_by_xpath('/html/body/table[2]/tbody/tr/td/table[2]/tbody/tr[2]/td[2]/p')\n",
    "        attribute_types.append(dataset_attr_type_obj.text)\n",
    "    except:\n",
    "        attribute_types.append('-')\n",
    "        \n",
    "   \n",
    "    #no of instances  \n",
    "    try:\n",
    "        dataset_instances_obj = driver.find_element_by_xpath('/html/body/table[2]/tbody/tr/td/table[2]/tbody/tr[1]/td[4]/p')\n",
    "        no_instances.append(dataset_instances_obj.text)\n",
    "    except:\n",
    "        no_instances.append('-')\n",
    "        \n",
    "     #no of attributes   \n",
    "        \n",
    "    try:\n",
    "        dataset_attr_obj = driver.find_element_by_xpath('/html/body/table[2]/tbody/tr/td/table[2]/tbody/tr[2]/td[4]/p')\n",
    "        no_attributes.append(dataset_attr_obj.text)\n",
    "    except:\n",
    "        no_attributes.append('-')\n",
    "    \n",
    "      \n",
    "    #year of DATASET\n",
    "    try:\n",
    "        year_obj = driver.find_element_by_xpath('/html/body/table[2]/tbody/tr/td/table[2]/tbody/tr[2]/td[6]/p')\n",
    "        year.append(year_obj.text)\n",
    "    except:\n",
    "        year.append('-')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATASET_NAME</th>\n",
       "      <th>DATASET_DATATYPE</th>\n",
       "      <th>DATA_TASK</th>\n",
       "      <th>ATTRIBUTe_TYPES</th>\n",
       "      <th>NO_OF_INSTANCEs</th>\n",
       "      <th>NO_OF_ATTRIBUTES</th>\n",
       "      <th>YEAR_DATSET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Parkinsons Data Set</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>197</td>\n",
       "      <td>197</td>\n",
       "      <td>2008-06-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Synchronous Machine Data Set Data Set</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Regression</td>\n",
       "      <td>Real</td>\n",
       "      <td>557</td>\n",
       "      <td>557</td>\n",
       "      <td>2021-04-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wikipedia Math Essentials Data Set</td>\n",
       "      <td>Time-Series</td>\n",
       "      <td>Regression</td>\n",
       "      <td>Real</td>\n",
       "      <td>731</td>\n",
       "      <td>731</td>\n",
       "      <td>2021-04-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wikipedia Math Essentials Data Set</td>\n",
       "      <td>Time-Series</td>\n",
       "      <td>Regression</td>\n",
       "      <td>Real</td>\n",
       "      <td>731</td>\n",
       "      <td>731</td>\n",
       "      <td>2021-04-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hungarian Chickenpox Cases Data Set</td>\n",
       "      <td>Time-Series</td>\n",
       "      <td>Regression</td>\n",
       "      <td>Real</td>\n",
       "      <td>521</td>\n",
       "      <td>521</td>\n",
       "      <td>2021-02-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Myocardial infarction complications Data Set</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>1700</td>\n",
       "      <td>1700</td>\n",
       "      <td>2020-12-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Gait Classification Data Set</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>2020-10-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Codon usage Data Set</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification, Clustering</td>\n",
       "      <td>N/A</td>\n",
       "      <td>13028</td>\n",
       "      <td>13028</td>\n",
       "      <td>2020-10-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>in-vehicle coupon recommendation Data Set</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>N/A</td>\n",
       "      <td>12684</td>\n",
       "      <td>12684</td>\n",
       "      <td>2020-09-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Dry Bean Dataset Data Set</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>13611</td>\n",
       "      <td>13611</td>\n",
       "      <td>2020-09-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Intelligent Media Accelerometer and Gyroscope ...</td>\n",
       "      <td>Time-Series</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>800</td>\n",
       "      <td>800</td>\n",
       "      <td>2020-09-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>AI4I 2020 Predictive Maintenance Dataset Data Set</td>\n",
       "      <td>Multivariate, Time-Series</td>\n",
       "      <td>Classification, Regression, Causal-Discovery</td>\n",
       "      <td>Real</td>\n",
       "      <td>10000</td>\n",
       "      <td>10000</td>\n",
       "      <td>2020-08-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Wisesight Sentiment Corpus Data Set</td>\n",
       "      <td>Multivariate, Text</td>\n",
       "      <td>Classification</td>\n",
       "      <td>N/A</td>\n",
       "      <td>26737</td>\n",
       "      <td>26737</td>\n",
       "      <td>2020-08-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Iris Data Set</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>150</td>\n",
       "      <td>150</td>\n",
       "      <td>1988-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Adult Data Set</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer</td>\n",
       "      <td>48842</td>\n",
       "      <td>48842</td>\n",
       "      <td>1996-05-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Wine Data Set</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>178</td>\n",
       "      <td>178</td>\n",
       "      <td>1991-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Wine Quality Data Set</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification, Regression</td>\n",
       "      <td>Real</td>\n",
       "      <td>4898</td>\n",
       "      <td>4898</td>\n",
       "      <td>2009-10-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Heart Disease Data Set</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>303</td>\n",
       "      <td>303</td>\n",
       "      <td>1988-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Breast Cancer Wisconsin (Diagnostic) Data Set</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>569</td>\n",
       "      <td>569</td>\n",
       "      <td>1995-11-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Bank Marketing Data Set</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>45211</td>\n",
       "      <td>45211</td>\n",
       "      <td>2012-02-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Car Evaluation Data Set</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>1728</td>\n",
       "      <td>1728</td>\n",
       "      <td>1997-06-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Human Activity Recognition Using Smartphones D...</td>\n",
       "      <td>Multivariate, Time-Series</td>\n",
       "      <td>Classification, Clustering</td>\n",
       "      <td>N/A</td>\n",
       "      <td>10299</td>\n",
       "      <td>10299</td>\n",
       "      <td>2012-12-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Abalone Data Set</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>4177</td>\n",
       "      <td>4177</td>\n",
       "      <td>1995-12-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Forest Fires Data Set</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Regression</td>\n",
       "      <td>Real</td>\n",
       "      <td>517</td>\n",
       "      <td>517</td>\n",
       "      <td>2008-02-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Student Performance Data Set</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification, Regression</td>\n",
       "      <td>Integer</td>\n",
       "      <td>649</td>\n",
       "      <td>649</td>\n",
       "      <td>2014-11-27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         DATASET_NAME  \\\n",
       "0                                 Parkinsons Data Set   \n",
       "1               Synchronous Machine Data Set Data Set   \n",
       "2                  Wikipedia Math Essentials Data Set   \n",
       "3                  Wikipedia Math Essentials Data Set   \n",
       "4                 Hungarian Chickenpox Cases Data Set   \n",
       "5        Myocardial infarction complications Data Set   \n",
       "6                        Gait Classification Data Set   \n",
       "7                                Codon usage Data Set   \n",
       "8           in-vehicle coupon recommendation Data Set   \n",
       "9                           Dry Bean Dataset Data Set   \n",
       "10  Intelligent Media Accelerometer and Gyroscope ...   \n",
       "11  AI4I 2020 Predictive Maintenance Dataset Data Set   \n",
       "12                Wisesight Sentiment Corpus Data Set   \n",
       "13                                      Iris Data Set   \n",
       "14                                     Adult Data Set   \n",
       "15                                      Wine Data Set   \n",
       "16                              Wine Quality Data Set   \n",
       "17                             Heart Disease Data Set   \n",
       "18      Breast Cancer Wisconsin (Diagnostic) Data Set   \n",
       "19                            Bank Marketing Data Set   \n",
       "20                            Car Evaluation Data Set   \n",
       "21  Human Activity Recognition Using Smartphones D...   \n",
       "22                                   Abalone Data Set   \n",
       "23                              Forest Fires Data Set   \n",
       "24                       Student Performance Data Set   \n",
       "\n",
       "             DATASET_DATATYPE                                     DATA_TASK  \\\n",
       "0                Multivariate                                Classification   \n",
       "1                Multivariate                                    Regression   \n",
       "2                 Time-Series                                    Regression   \n",
       "3                 Time-Series                                    Regression   \n",
       "4                 Time-Series                                    Regression   \n",
       "5                Multivariate                                Classification   \n",
       "6                Multivariate                                Classification   \n",
       "7                Multivariate                    Classification, Clustering   \n",
       "8                Multivariate                                Classification   \n",
       "9                Multivariate                                Classification   \n",
       "10                Time-Series                                Classification   \n",
       "11  Multivariate, Time-Series  Classification, Regression, Causal-Discovery   \n",
       "12         Multivariate, Text                                Classification   \n",
       "13               Multivariate                                Classification   \n",
       "14               Multivariate                                Classification   \n",
       "15               Multivariate                                Classification   \n",
       "16               Multivariate                    Classification, Regression   \n",
       "17               Multivariate                                Classification   \n",
       "18               Multivariate                                Classification   \n",
       "19               Multivariate                                Classification   \n",
       "20               Multivariate                                Classification   \n",
       "21  Multivariate, Time-Series                    Classification, Clustering   \n",
       "22               Multivariate                                Classification   \n",
       "23               Multivariate                                    Regression   \n",
       "24               Multivariate                    Classification, Regression   \n",
       "\n",
       "               ATTRIBUTe_TYPES NO_OF_INSTANCEs NO_OF_ATTRIBUTES YEAR_DATSET  \n",
       "0                         Real             197              197  2008-06-26  \n",
       "1                         Real             557              557  2021-04-21  \n",
       "2                         Real             731              731  2021-04-20  \n",
       "3                         Real             731              731  2021-04-20  \n",
       "4                         Real             521              521  2021-02-17  \n",
       "5                         Real            1700             1700  2020-12-09  \n",
       "6                         Real              48               48  2020-10-14  \n",
       "7                          N/A           13028            13028  2020-10-03  \n",
       "8                          N/A           12684            12684  2020-09-15  \n",
       "9                Integer, Real           13611            13611  2020-09-14  \n",
       "10                        Real             800              800  2020-09-03  \n",
       "11                        Real           10000            10000  2020-08-30  \n",
       "12                         N/A           26737            26737  2020-08-25  \n",
       "13                        Real             150              150  1988-07-01  \n",
       "14        Categorical, Integer           48842            48842  1996-05-01  \n",
       "15               Integer, Real             178              178  1991-07-01  \n",
       "16                        Real            4898             4898  2009-10-07  \n",
       "17  Categorical, Integer, Real             303              303  1988-07-01  \n",
       "18                        Real             569              569  1995-11-01  \n",
       "19                        Real           45211            45211  2012-02-14  \n",
       "20                 Categorical            1728             1728  1997-06-01  \n",
       "21                         N/A           10299            10299  2012-12-10  \n",
       "22  Categorical, Integer, Real            4177             4177  1995-12-01  \n",
       "23                        Real             517              517  2008-02-29  \n",
       "24                     Integer             649              649  2014-11-27  "
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating a dictionary of all the elements\n",
    "dict = {\n",
    "    'DATASET_NAME': dataset_names, 'DATASET_DATATYPE':dataset_datatypes,'DATA_TASK':tasks,\n",
    "    'ATTRIBUTe_TYPES':attribute_types, 'NO_OF_INSTANCEs':no_instances,\n",
    "    'NO_OF_ATTRIBUTES':no_instances,'YEAR_DATSET':year\n",
    "}\n",
    "\n",
    "#creating a Table from the dictionary\n",
    "table = pd.DataFrame(dict)\n",
    "table"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
